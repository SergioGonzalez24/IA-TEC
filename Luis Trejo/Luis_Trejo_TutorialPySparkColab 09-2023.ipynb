{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kbRRaZlBt6Nh",
        "h-buZtUBtnOp",
        "ikvKjBuY6e7-",
        "7_zMjiAbClef",
        "MHhiL2rneKF5",
        "wJ4qq4PRBWK3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 1: Configuración y carga de datos en PySpark SEP 2023"
      ],
      "metadata": {
        "id": "kbRRaZlBt6Nh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 1: Configuración del entorno de PySpark en Colab"
      ],
      "metadata": {
        "id": "K6Iv32T_kgRf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "sKfMHXDwiZqF",
        "outputId": "13935ccc-b68f-45ed-8ebc-c155aec7c643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\u001b[0m\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\u001b[33m\r0% [Waiting for headers] [2 InRelease 14.2 kB/110 kB 13%] [Waiting for headers]\u001b[0m\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [2 InRelease 14.2 kB/110 kB 13%] [Connecting to ppa.la\u001b[0m\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,260 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,283 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 2,772 kB in 2s (1,357 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "19 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.5.0-bin-hadoop3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "#Bibliotecas para poder trabajar con Spark\n",
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#!wget -q https://downloads.apache.org/spark/spark-3.2.2/spark-3.2.2-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "\n",
        "#!tar xf spark-3.2.2-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "\n",
        "#Configuración de Spark con Python\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "\n",
        "#Estableciendo variable de entorno\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.2-bin-hadoop3.2\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "\n",
        "#Buscando e inicializando la instalación de Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 2: Selección y vista de los datos"
      ],
      "metadata": {
        "id": "3-DE0eskkyRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('sample_data/california_housing_test.csv')"
      ],
      "metadata": {
        "id": "ywqxFXoXJiv0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "jH2hpm6PJYUK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "1817ecab-fc0c-4b8e-b990-af004aba1f1a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0       -122.05     37.37                27.0       3885.0           661.0   \n",
              "1       -118.30     34.26                43.0       1510.0           310.0   \n",
              "2       -117.81     33.78                27.0       3589.0           507.0   \n",
              "3       -118.36     33.82                28.0         67.0            15.0   \n",
              "4       -119.67     36.33                19.0       1241.0           244.0   \n",
              "...         ...       ...                 ...          ...             ...   \n",
              "2995    -119.86     34.42                23.0       1450.0           642.0   \n",
              "2996    -118.14     34.06                27.0       5257.0          1082.0   \n",
              "2997    -119.70     36.30                10.0        956.0           201.0   \n",
              "2998    -117.12     34.10                40.0         96.0            14.0   \n",
              "2999    -119.63     34.42                42.0       1765.0           263.0   \n",
              "\n",
              "      population  households  median_income  median_house_value  \n",
              "0         1537.0       606.0         6.6085            344700.0  \n",
              "1          809.0       277.0         3.5990            176500.0  \n",
              "2         1484.0       495.0         5.7934            270500.0  \n",
              "3           49.0        11.0         6.1359            330000.0  \n",
              "4          850.0       237.0         2.9375             81700.0  \n",
              "...          ...         ...            ...                 ...  \n",
              "2995      1258.0       607.0         1.1790            225000.0  \n",
              "2996      3496.0      1036.0         3.3906            237200.0  \n",
              "2997       693.0       220.0         2.2895             62000.0  \n",
              "2998        46.0        14.0         3.2708            162500.0  \n",
              "2999       753.0       260.0         8.5608            500001.0  \n",
              "\n",
              "[3000 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c40ae56-555c-45a6-a658-e7189e415978\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.05</td>\n",
              "      <td>37.37</td>\n",
              "      <td>27.0</td>\n",
              "      <td>3885.0</td>\n",
              "      <td>661.0</td>\n",
              "      <td>1537.0</td>\n",
              "      <td>606.0</td>\n",
              "      <td>6.6085</td>\n",
              "      <td>344700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-118.30</td>\n",
              "      <td>34.26</td>\n",
              "      <td>43.0</td>\n",
              "      <td>1510.0</td>\n",
              "      <td>310.0</td>\n",
              "      <td>809.0</td>\n",
              "      <td>277.0</td>\n",
              "      <td>3.5990</td>\n",
              "      <td>176500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-117.81</td>\n",
              "      <td>33.78</td>\n",
              "      <td>27.0</td>\n",
              "      <td>3589.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>1484.0</td>\n",
              "      <td>495.0</td>\n",
              "      <td>5.7934</td>\n",
              "      <td>270500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-118.36</td>\n",
              "      <td>33.82</td>\n",
              "      <td>28.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.1359</td>\n",
              "      <td>330000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-119.67</td>\n",
              "      <td>36.33</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1241.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>850.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>2.9375</td>\n",
              "      <td>81700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>-119.86</td>\n",
              "      <td>34.42</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1450.0</td>\n",
              "      <td>642.0</td>\n",
              "      <td>1258.0</td>\n",
              "      <td>607.0</td>\n",
              "      <td>1.1790</td>\n",
              "      <td>225000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>-118.14</td>\n",
              "      <td>34.06</td>\n",
              "      <td>27.0</td>\n",
              "      <td>5257.0</td>\n",
              "      <td>1082.0</td>\n",
              "      <td>3496.0</td>\n",
              "      <td>1036.0</td>\n",
              "      <td>3.3906</td>\n",
              "      <td>237200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>-119.70</td>\n",
              "      <td>36.30</td>\n",
              "      <td>10.0</td>\n",
              "      <td>956.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>693.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>2.2895</td>\n",
              "      <td>62000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>-117.12</td>\n",
              "      <td>34.10</td>\n",
              "      <td>40.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3.2708</td>\n",
              "      <td>162500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>-119.63</td>\n",
              "      <td>34.42</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1765.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>753.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>8.5608</td>\n",
              "      <td>500001.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c40ae56-555c-45a6-a658-e7189e415978')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c40ae56-555c-45a6-a658-e7189e415978 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c40ae56-555c-45a6-a658-e7189e415978');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0b59e0c1-79a4-4334-bd78-2451f4b11e45\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b59e0c1-79a4-4334-bd78-2451f4b11e45')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0b59e0c1-79a4-4334-bd78-2451f4b11e45 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 3: Crear la sesión de trabajo de Spark\n",
        "\n",
        "Ya seleccionado y visto el conjunto de datos comencemos a trabajar con PySpark. Para comenzar a trabajar con PySpark, debemos iniciar la sesión de Spark. Para esto realizaremos lo siguiente:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.   Importar SparkSession\n",
        "2.   Crear la sesión\n",
        "\n"
      ],
      "metadata": {
        "id": "Px0CvEobk43I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Verificar la funcionalidad de Pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark_session = SparkSession.builder.appName('PySpark_LuisTrejo1').getOrCreate()\n",
        "spark_session"
      ],
      "metadata": {
        "id": "hqEN5b1eKRTn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "19a4dcc3-1c99-424f-f623-1eeaaadaa004"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x782ed5c729b0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://1040695525b7:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark_LuisTrejo1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La SparkSession contiene los siguiente elementos:\n",
        "\n",
        "\n",
        "*   Version: La versión de Spark\n",
        "*   Master: Como estamos trabajando en un sistema en la nube pero no distribuido nos devuelve local, sin embargo, si tuvieramos un sistema distribuido aquí entonces podríamos tener diferentes clústeres, así como primero habrá un maestro y luego una estructura similar a un árbol (cluster_1, cluster_2 ... cluster_n).\n",
        "*   AppName: Nombre de la aplicación."
      ],
      "metadata": {
        "id": "mbRahpVtmPBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 4: Cargar los datos para manipularlos dentro de Spark"
      ],
      "metadata": {
        "id": "iADBYL1_tvfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark = spark_session.read.csv('sample_data/california_housing_train.csv')\n",
        "df_spark"
      ],
      "metadata": {
        "id": "qJdqDvH1Ke0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8480f5-df46-479a-d19a-04f3fe546fe5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string, _c6: string, _c7: string, _c8: string]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el caso de PySpark para visualizar los datos tenemos la función *show()* ques similar a *head()* de pandas con algunas diferencias como:\n",
        "\n",
        "\n",
        "1.   Mostrar 20 registro en lugar de 5\n",
        "2.   La apariencia de los datos\n",
        "3.   En lugar de tomar la primera fila como encabezados la incluye como un registro y coloca _c1 a _cn como nombre de la columna.\n",
        "\n"
      ],
      "metadata": {
        "id": "OkNMWmBnm6QO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.show()"
      ],
      "metadata": {
        "id": "zT2_YaGFnynL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b65eb9af-faf0-4465-bffc-4aadb38b5ac7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "|        _c0|      _c1|               _c2|        _c3|           _c4|        _c5|        _c6|          _c7|               _c8|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population| households|median_income|median_house_value|\n",
            "|-114.310000|34.190000|         15.000000|5612.000000|   1283.000000|1015.000000| 472.000000|     1.493600|      66900.000000|\n",
            "|-114.470000|34.400000|         19.000000|7650.000000|   1901.000000|1129.000000| 463.000000|     1.820000|      80100.000000|\n",
            "|-114.560000|33.690000|         17.000000| 720.000000|    174.000000| 333.000000| 117.000000|     1.650900|      85700.000000|\n",
            "|-114.570000|33.640000|         14.000000|1501.000000|    337.000000| 515.000000| 226.000000|     3.191700|      73400.000000|\n",
            "|-114.570000|33.570000|         20.000000|1454.000000|    326.000000| 624.000000| 262.000000|     1.925000|      65500.000000|\n",
            "|-114.580000|33.630000|         29.000000|1387.000000|    236.000000| 671.000000| 239.000000|     3.343800|      74000.000000|\n",
            "|-114.580000|33.610000|         25.000000|2907.000000|    680.000000|1841.000000| 633.000000|     2.676800|      82400.000000|\n",
            "|-114.590000|34.830000|         41.000000| 812.000000|    168.000000| 375.000000| 158.000000|     1.708300|      48500.000000|\n",
            "|-114.590000|33.610000|         34.000000|4789.000000|   1175.000000|3134.000000|1056.000000|     2.178200|      58400.000000|\n",
            "|-114.600000|34.830000|         46.000000|1497.000000|    309.000000| 787.000000| 271.000000|     2.190800|      48100.000000|\n",
            "|-114.600000|33.620000|         16.000000|3741.000000|    801.000000|2434.000000| 824.000000|     2.679700|      86500.000000|\n",
            "|-114.600000|33.600000|         21.000000|1988.000000|    483.000000|1182.000000| 437.000000|     1.625000|      62000.000000|\n",
            "|-114.610000|34.840000|         48.000000|1291.000000|    248.000000| 580.000000| 211.000000|     2.157100|      48600.000000|\n",
            "|-114.610000|34.830000|         31.000000|2478.000000|    464.000000|1346.000000| 479.000000|     3.212000|      70400.000000|\n",
            "|-114.630000|32.760000|         15.000000|1448.000000|    378.000000| 949.000000| 300.000000|     0.858500|      45000.000000|\n",
            "|-114.650000|34.890000|         17.000000|2556.000000|    587.000000|1005.000000| 401.000000|     1.699100|      69100.000000|\n",
            "|-114.650000|33.600000|         28.000000|1678.000000|    322.000000| 666.000000| 256.000000|     2.965300|      94900.000000|\n",
            "|-114.650000|32.790000|         21.000000|  44.000000|     33.000000|  64.000000|  27.000000|     0.857100|      25000.000000|\n",
            "|-114.660000|32.740000|         17.000000|1388.000000|    386.000000| 775.000000| 320.000000|     1.204900|      44000.000000|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si queremos integrar la primera fila como los nombres de las columnas hay que agregar una opción a la hora de cargar los datos en el DataFrame."
      ],
      "metadata": {
        "id": "xoQGO2FxmtNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#La opción option('header','true')\n",
        "df_spark_col  = spark_session.read.option('header', 'true').csv('sample_data/california_housing_train.csv')\n",
        "df_spark_col"
      ],
      "metadata": {
        "id": "37zvYB-onzJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c7d95a5-1db4-4088-cad3-fb4efb345c92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[longitude: string, latitude: string, housing_median_age: string, total_rooms: string, total_bedrooms: string, population: string, households: string, median_income: string, median_house_value: string]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark_col.show()"
      ],
      "metadata": {
        "id": "w52J4vd0oIT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "042992ac-e447-45ab-f24c-eab23e49b730"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population| households|median_income|median_house_value|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "|-114.310000|34.190000|         15.000000|5612.000000|   1283.000000|1015.000000| 472.000000|     1.493600|      66900.000000|\n",
            "|-114.470000|34.400000|         19.000000|7650.000000|   1901.000000|1129.000000| 463.000000|     1.820000|      80100.000000|\n",
            "|-114.560000|33.690000|         17.000000| 720.000000|    174.000000| 333.000000| 117.000000|     1.650900|      85700.000000|\n",
            "|-114.570000|33.640000|         14.000000|1501.000000|    337.000000| 515.000000| 226.000000|     3.191700|      73400.000000|\n",
            "|-114.570000|33.570000|         20.000000|1454.000000|    326.000000| 624.000000| 262.000000|     1.925000|      65500.000000|\n",
            "|-114.580000|33.630000|         29.000000|1387.000000|    236.000000| 671.000000| 239.000000|     3.343800|      74000.000000|\n",
            "|-114.580000|33.610000|         25.000000|2907.000000|    680.000000|1841.000000| 633.000000|     2.676800|      82400.000000|\n",
            "|-114.590000|34.830000|         41.000000| 812.000000|    168.000000| 375.000000| 158.000000|     1.708300|      48500.000000|\n",
            "|-114.590000|33.610000|         34.000000|4789.000000|   1175.000000|3134.000000|1056.000000|     2.178200|      58400.000000|\n",
            "|-114.600000|34.830000|         46.000000|1497.000000|    309.000000| 787.000000| 271.000000|     2.190800|      48100.000000|\n",
            "|-114.600000|33.620000|         16.000000|3741.000000|    801.000000|2434.000000| 824.000000|     2.679700|      86500.000000|\n",
            "|-114.600000|33.600000|         21.000000|1988.000000|    483.000000|1182.000000| 437.000000|     1.625000|      62000.000000|\n",
            "|-114.610000|34.840000|         48.000000|1291.000000|    248.000000| 580.000000| 211.000000|     2.157100|      48600.000000|\n",
            "|-114.610000|34.830000|         31.000000|2478.000000|    464.000000|1346.000000| 479.000000|     3.212000|      70400.000000|\n",
            "|-114.630000|32.760000|         15.000000|1448.000000|    378.000000| 949.000000| 300.000000|     0.858500|      45000.000000|\n",
            "|-114.650000|34.890000|         17.000000|2556.000000|    587.000000|1005.000000| 401.000000|     1.699100|      69100.000000|\n",
            "|-114.650000|33.600000|         28.000000|1678.000000|    322.000000| 666.000000| 256.000000|     2.965300|      94900.000000|\n",
            "|-114.650000|32.790000|         21.000000|  44.000000|     33.000000|  64.000000|  27.000000|     0.857100|      25000.000000|\n",
            "|-114.660000|32.740000|         17.000000|1388.000000|    386.000000| 775.000000| 320.000000|     1.204900|      44000.000000|\n",
            "|-114.670000|33.920000|         17.000000|  97.000000|     24.000000|  29.000000|  15.000000|     1.265600|      27500.000000|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como comparativa entre Pandas y PySpark ambos manejan la información dentro de DataFrames pero la función *show()* solo es aplicable en Spark mientras que *head()* funciona en ambos"
      ],
      "metadata": {
        "id": "SkGw3U3UpiD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(df_spark_col))\n",
        "print(type(data))"
      ],
      "metadata": {
        "id": "OBoQNiUVoSD4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83da0e28-c5b8-408f-bf38-ae848fb29043"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función *head()* muestra por cada columna el valor que tiene, sin embargo muestra la información por fila utilizando este formato mencionado"
      ],
      "metadata": {
        "id": "M4l2FDVMqRI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark_col.head(10)"
      ],
      "metadata": {
        "id": "B2FAh9QDoha_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7846e96c-d6a4-44cb-8728-08842b864e57"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(longitude='-114.310000', latitude='34.190000', housing_median_age='15.000000', total_rooms='5612.000000', total_bedrooms='1283.000000', population='1015.000000', households='472.000000', median_income='1.493600', median_house_value='66900.000000'),\n",
              " Row(longitude='-114.470000', latitude='34.400000', housing_median_age='19.000000', total_rooms='7650.000000', total_bedrooms='1901.000000', population='1129.000000', households='463.000000', median_income='1.820000', median_house_value='80100.000000'),\n",
              " Row(longitude='-114.560000', latitude='33.690000', housing_median_age='17.000000', total_rooms='720.000000', total_bedrooms='174.000000', population='333.000000', households='117.000000', median_income='1.650900', median_house_value='85700.000000'),\n",
              " Row(longitude='-114.570000', latitude='33.640000', housing_median_age='14.000000', total_rooms='1501.000000', total_bedrooms='337.000000', population='515.000000', households='226.000000', median_income='3.191700', median_house_value='73400.000000'),\n",
              " Row(longitude='-114.570000', latitude='33.570000', housing_median_age='20.000000', total_rooms='1454.000000', total_bedrooms='326.000000', population='624.000000', households='262.000000', median_income='1.925000', median_house_value='65500.000000'),\n",
              " Row(longitude='-114.580000', latitude='33.630000', housing_median_age='29.000000', total_rooms='1387.000000', total_bedrooms='236.000000', population='671.000000', households='239.000000', median_income='3.343800', median_house_value='74000.000000'),\n",
              " Row(longitude='-114.580000', latitude='33.610000', housing_median_age='25.000000', total_rooms='2907.000000', total_bedrooms='680.000000', population='1841.000000', households='633.000000', median_income='2.676800', median_house_value='82400.000000'),\n",
              " Row(longitude='-114.590000', latitude='34.830000', housing_median_age='41.000000', total_rooms='812.000000', total_bedrooms='168.000000', population='375.000000', households='158.000000', median_income='1.708300', median_house_value='48500.000000'),\n",
              " Row(longitude='-114.590000', latitude='33.610000', housing_median_age='34.000000', total_rooms='4789.000000', total_bedrooms='1175.000000', population='3134.000000', households='1056.000000', median_income='2.178200', median_house_value='58400.000000'),\n",
              " Row(longitude='-114.600000', latitude='34.830000', housing_median_age='46.000000', total_rooms='1497.000000', total_bedrooms='309.000000', population='787.000000', households='271.000000', median_income='2.190800', median_house_value='48100.000000')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si queremos saber información acerca de los datos utilizamos la función *printSchema()* la cual muestra el nombre de cada columna, su tipo de dato y si permite valores nulos"
      ],
      "metadata": {
        "id": "4tNzS6dPrfns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark_col.printSchema()"
      ],
      "metadata": {
        "id": "_bdNEtSRokEQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28eb968b-1ac2-42c9-c4f2-ad939cbd2469"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- longitude: string (nullable = true)\n",
            " |-- latitude: string (nullable = true)\n",
            " |-- housing_median_age: string (nullable = true)\n",
            " |-- total_rooms: string (nullable = true)\n",
            " |-- total_bedrooms: string (nullable = true)\n",
            " |-- population: string (nullable = true)\n",
            " |-- households: string (nullable = true)\n",
            " |-- median_income: string (nullable = true)\n",
            " |-- median_house_value: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tutorial 2: Consultas en DataFrame dentro de PySpark"
      ],
      "metadata": {
        "id": "h-buZtUBtnOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('OperacionesFiltrado').getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "id": "tgvc4GJCqYPD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "97cd53bd-1207-4f65-98fc-c0a3dbd8c59e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x782ed5c729b0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://1040695525b7:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark_LuisTrejo1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cargar la información usaremos solamente la función *csv()* pero agregando parámetros de configuración para que tome el primer registro como los nombres de las columnas y tambien que a partir de los datos de entrada infiera el tipo de dato. Si no colocamos esto automáticamente considera de tipo *string* las columnas."
      ],
      "metadata": {
        "id": "Xa09MN6CwPEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter_pyspark = spark.read.csv('part2.csv', header = True, inferSchema=True)\n",
        "df_filter_pyspark.show()"
      ],
      "metadata": {
        "id": "n87v4tRhqpZe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45bb227d-b73e-4640-d401-f116feaad3ef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|        Oscar|           NULL|                 NULL|                 40000|\n",
            "|         NULL|             34|                   10|                 38000|\n",
            "|         NULL|             36|                 NULL|                  NULL|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter_pyspark.printSchema()"
      ],
      "metadata": {
        "id": "4neGDBsyvX-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a5793f7-ea58-4371-9065-5183ab867395"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Employee Name: string (nullable = true)\n",
            " |-- Age of Employee: integer (nullable = true)\n",
            " |-- Experience (in years): integer (nullable = true)\n",
            " |-- Salary (per month - $): integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si se necesita podemos renombrar las columnas para referirnos a ellas de una forma más sencilla o simplificada con la función *withColumnRenamed()*."
      ],
      "metadata": {
        "id": "uWV3LXYuw0IQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtros y selección"
      ],
      "metadata": {
        "id": "mr5GDyV93GOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter_pyspark= df_filter_pyspark.withColumnRenamed(\"Salary (per month - $)\",\"EmpSalary\")\n",
        "df_filter_pyspark.show()"
      ],
      "metadata": {
        "id": "_B5aqNbGrK_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66936579-b538-4b26-a765-409dd8382f38"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+---------------------+---------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "|       Oliver|             31|                   10|    30000|\n",
            "|        Harry|             30|                    8|    25000|\n",
            "|       George|             29|                    4|    20000|\n",
            "|         Jack|             24|                    3|    20000|\n",
            "|        Jacob|             21|                    1|    15000|\n",
            "|          Leo|             23|                    2|    18000|\n",
            "|        Oscar|           NULL|                 NULL|    40000|\n",
            "|         NULL|             34|                   10|    38000|\n",
            "|         NULL|             36|                 NULL|     NULL|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "La función *filter()* nos permite filtrar la información a través de condiciones. Por ejemplo, vamos a mostrar unicamente aquellos empleados que tengan un salario menor o igual a $25,000.00."
      ],
      "metadata": {
        "id": "fUV8l1eWy90u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter_pyspark.filter(\"EmpSalary<=25000\").show()"
      ],
      "metadata": {
        "id": "FGGtrHVxq1qB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bacd9137-15e1-43ce-bd09-1743b0fbd6cd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+---------------------+---------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "|        Harry|             30|                    8|    25000|\n",
            "|       George|             29|                    4|    20000|\n",
            "|         Jack|             24|                    3|    20000|\n",
            "|        Jacob|             21|                    1|    15000|\n",
            "|          Leo|             23|                    2|    18000|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como pudieron observar hay una cierta similitud de la función *filter()* con SELECT de SQL. Es por eso que se pueden utilizar consultas SQL y tratar los DataFrames como tablas o vistas de un modelo relacional. La función *createOrReplaceTempView()* registra el DataFrame como una vista temporal dentro de la sesión que puede ejecutar consutlas SQL."
      ],
      "metadata": {
        "id": "gO6txvqVzdZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter_pyspark.createOrReplaceTempView(\"empleados\")\n",
        "sqlDF = spark.sql(\"SELECT * FROM empleados\")\n",
        "sqlDF.show()"
      ],
      "metadata": {
        "id": "CSkcljBNxiKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c406498-d175-4c12-8b04-25aa793ac19d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+---------------------+---------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "|       Oliver|             31|                   10|    30000|\n",
            "|        Harry|             30|                    8|    25000|\n",
            "|       George|             29|                    4|    20000|\n",
            "|         Jack|             24|                    3|    20000|\n",
            "|        Jacob|             21|                    1|    15000|\n",
            "|          Leo|             23|                    2|    18000|\n",
            "|        Oscar|           NULL|                 NULL|    40000|\n",
            "|         NULL|             34|                   10|    38000|\n",
            "|         NULL|             36|                 NULL|     NULL|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si la vista temporal que se produce quieren que sea utilizada en multiples sesiones entonces hay que utilizar la función *createGlobalTempView()*. El unico detalle es que la vista quedará anclada a una base de datos llamada *global_temp*."
      ],
      "metadata": {
        "id": "_4UHtcD20q8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter_pyspark.createGlobalTempView(\"g_empleados\")\n",
        "sqlDF = spark.sql(\"SELECT * FROM global_temp.g_empleados\")\n",
        "sqlDF.show()"
      ],
      "metadata": {
        "id": "oNc4FMzG1Rln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed07908-03c0-4a82-d373-cf1243a91f7d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+---------------------+---------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "|       Oliver|             31|                   10|    30000|\n",
            "|        Harry|             30|                    8|    25000|\n",
            "|       George|             29|                    4|    20000|\n",
            "|         Jack|             24|                    3|    20000|\n",
            "|        Jacob|             21|                    1|    15000|\n",
            "|          Leo|             23|                    2|    18000|\n",
            "|        Oscar|           NULL|                 NULL|    40000|\n",
            "|         NULL|             34|                   10|    38000|\n",
            "|         NULL|             36|                 NULL|     NULL|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como mencionamos la vista perdura en otras sesiones."
      ],
      "metadata": {
        "id": "6ATcN_3S1162"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.newSession().sql(\"SELECT * FROM global_temp.g_empleados\").show()"
      ],
      "metadata": {
        "id": "cR9qBGWh1-rz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3712d2bf-014a-40af-9657-323189494645"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+---------------------+---------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "|       Oliver|             31|                   10|    30000|\n",
            "|        Harry|             30|                    8|    25000|\n",
            "|       George|             29|                    4|    20000|\n",
            "|         Jack|             24|                    3|    20000|\n",
            "|        Jacob|             21|                    1|    15000|\n",
            "|          Leo|             23|                    2|    18000|\n",
            "|        Oscar|           NULL|                 NULL|    40000|\n",
            "|         NULL|             34|                   10|    38000|\n",
            "|         NULL|             36|                 NULL|     NULL|\n",
            "+-------------+---------------+---------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede de igual forma cambiar el nombre de multiples columnas al mismo tiempo."
      ],
      "metadata": {
        "id": "lOw7X7R92H1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cambiamos el nombre de multiples columnas\n",
        "df_filter_pyspark= df_filter_pyspark.withColumnRenamed(\"Age of Employee\",\"EmpAge\").withColumnRenamed(\"Employee Name\",\"EmpName\")\n",
        "df_filter_pyspark.show()"
      ],
      "metadata": {
        "id": "_vkSgApfrlzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb6f1f4-80a5-4a7c-bcec-71c4b983d477"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+---------------------+---------+\n",
            "|EmpName|EmpAge|Experience (in years)|EmpSalary|\n",
            "+-------+------+---------------------+---------+\n",
            "| Oliver|    31|                   10|    30000|\n",
            "|  Harry|    30|                    8|    25000|\n",
            "| George|    29|                    4|    20000|\n",
            "|   Jack|    24|                    3|    20000|\n",
            "|  Jacob|    21|                    1|    15000|\n",
            "|    Leo|    23|                    2|    18000|\n",
            "|  Oscar|  NULL|                 NULL|    40000|\n",
            "|   NULL|    34|                   10|    38000|\n",
            "|   NULL|    36|                 NULL|     NULL|\n",
            "+-------+------+---------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al igual que en SQL se pueden seleccionar las columnas que serán mostradas dentro de la consulta acompañando a la función *filter()* con la función *select()*."
      ],
      "metadata": {
        "id": "73Rl2uG32Q_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter_pyspark.filter(\"EmpSalary<=25000\").select(['EmpName','EmpAge']).show()"
      ],
      "metadata": {
        "id": "tGtFqXeyri3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e38ac823-5a0c-4f0b-a057-e03760df3789"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+\n",
            "|EmpName|EmpAge|\n",
            "+-------+------+\n",
            "|  Harry|    30|\n",
            "| George|    29|\n",
            "|   Jack|    24|\n",
            "|  Jacob|    21|\n",
            "|    Leo|    23|\n",
            "+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra manera de filtrar la información de los registros es utilizar un estilo similar a Pandas."
      ],
      "metadata": {
        "id": "NXx1CwoD2sW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter_pyspark.filter(df_filter_pyspark['EmpSalary']<=25000).select(['EmpName','EmpAge']).show()"
      ],
      "metadata": {
        "id": "LOZuURvRr4HZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c35ce46-b4e3-451c-8432-00ce6b694ed7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+\n",
            "|EmpName|EmpAge|\n",
            "+-------+------+\n",
            "|  Harry|    30|\n",
            "| George|    29|\n",
            "|   Jack|    24|\n",
            "|  Jacob|    21|\n",
            "|    Leo|    23|\n",
            "+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Operadores Lógicos"
      ],
      "metadata": {
        "id": "FlPM5Da224mk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los operadores lógicos disponibles son AND (&), OR (|) y NOT (~)."
      ],
      "metadata": {
        "id": "pHT4extP4NfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo con AND: Los empleados que su salario sea menor o igual a \\$30,000.00 y que sea mayor o igual a \\$18,000.00."
      ],
      "metadata": {
        "id": "gOTdAcq64fFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter_pyspark.filter((df_filter_pyspark['EmpSalary']<=30000)\n",
        "                          & (df_filter_pyspark['EmpSalary']>=18000)).show()"
      ],
      "metadata": {
        "id": "vYgWyHBUsDw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d4e659-5541-4eac-c40b-b4a3e1b78ffb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+---------------------+---------+\n",
            "|EmpName|EmpAge|Experience (in years)|EmpSalary|\n",
            "+-------+------+---------------------+---------+\n",
            "| Oliver|    31|                   10|    30000|\n",
            "|  Harry|    30|                    8|    25000|\n",
            "| George|    29|                    4|    20000|\n",
            "|   Jack|    24|                    3|    20000|\n",
            "|    Leo|    23|                    2|    18000|\n",
            "+-------+------+---------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cambiamos el nombre de la columna experiencia\n",
        "df_filter_pyspark= df_filter_pyspark.withColumnRenamed(\"Experience (in years)\",\"EmpExperience\")\n",
        "df_filter_pyspark.show()"
      ],
      "metadata": {
        "id": "FjuqaJ80syOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12aabb3-08c6-4e60-8b82-ed9dfcad3a20"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-------------+---------+\n",
            "|EmpName|EmpAge|EmpExperience|EmpSalary|\n",
            "+-------+------+-------------+---------+\n",
            "| Oliver|    31|           10|    30000|\n",
            "|  Harry|    30|            8|    25000|\n",
            "| George|    29|            4|    20000|\n",
            "|   Jack|    24|            3|    20000|\n",
            "|  Jacob|    21|            1|    15000|\n",
            "|    Leo|    23|            2|    18000|\n",
            "|  Oscar|  NULL|         NULL|    40000|\n",
            "|   NULL|    34|           10|    38000|\n",
            "|   NULL|    36|         NULL|     NULL|\n",
            "+-------+------+-------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo con OR: Los empleados que su salario sea menor o igual a \\$30,000.00 ó que su experiencia laboral sea mayor o igual a 3 años."
      ],
      "metadata": {
        "id": "latXscc144pR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter_pyspark.filter((df_filter_pyspark['EmpSalary']<=30000)\n",
        "                          | (df_filter_pyspark['EmpExperience']>=3)).show()"
      ],
      "metadata": {
        "id": "WxIIaEmvsvvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55d8c27-c30a-49d1-bc75-b60014b0e3cb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-------------+---------+\n",
            "|EmpName|EmpAge|EmpExperience|EmpSalary|\n",
            "+-------+------+-------------+---------+\n",
            "| Oliver|    31|           10|    30000|\n",
            "|  Harry|    30|            8|    25000|\n",
            "| George|    29|            4|    20000|\n",
            "|   Jack|    24|            3|    20000|\n",
            "|  Jacob|    21|            1|    15000|\n",
            "|    Leo|    23|            2|    18000|\n",
            "|   NULL|    34|           10|    38000|\n",
            "+-------+------+-------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo NOT: Los empleandos que su edad no sea mayor o igual a 30 años."
      ],
      "metadata": {
        "id": "WFxPQ4OL5YIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter_pyspark.filter(~(df_filter_pyspark['EmpAge']>=30)).show()"
      ],
      "metadata": {
        "id": "ohEM94QPs9UE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834be1ba-7770-4b9c-9533-9ba11ff1decd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-------------+---------+\n",
            "|EmpName|EmpAge|EmpExperience|EmpSalary|\n",
            "+-------+------+-------------+---------+\n",
            "| George|    29|            4|    20000|\n",
            "|   Jack|    24|            3|    20000|\n",
            "|  Jacob|    21|            1|    15000|\n",
            "|    Leo|    23|            2|    18000|\n",
            "+-------+------+-------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 3: Manejo de valores nulos"
      ],
      "metadata": {
        "id": "ikvKjBuY6e7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creamos una sesión de PySpark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "null_spark = SparkSession.builder.appName('ValoresNulos').getOrCreate()\n",
        "null_spark"
      ],
      "metadata": {
        "id": "2WFOahsM6utd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "44c281f5-9ccc-49b9-bc27-1be3860f6b7e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x782ed5c729b0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://1040695525b7:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark_LuisTrejo1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos los datos dentro de un DataFrame de la sesión\n",
        "df_null_pyspark = null_spark.read.csv('part2.csv', header = True, inferSchema = True)\n",
        "df_null_pyspark"
      ],
      "metadata": {
        "id": "O5TJdLAp7ASc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f93aa81-be76-4328-8624-4ffc48be3d44"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Employee Name: string, Age of Employee: int, Experience (in years): int, Salary (per month - $): int]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizamos la información\n",
        "df_null_pyspark.show()"
      ],
      "metadata": {
        "id": "8NXstlu57QSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "968f38ce-2fee-4cb9-e369-d9e806cabd66"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|        Oscar|           NULL|                 NULL|                 40000|\n",
            "|         NULL|             34|                   10|                 38000|\n",
            "|         NULL|             36|                 NULL|                  NULL|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nuevamente vemos la estructura de la información\n",
        "# recordando que cuando tenemos nullable = true significa que esa columna permite\n",
        "# valores nulos\n",
        "df_null_pyspark.printSchema()"
      ],
      "metadata": {
        "id": "eAflsQi47elO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb3b7fb5-90df-4d7d-b32b-f8a168dbfdaf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Employee Name: string (nullable = true)\n",
            " |-- Age of Employee: integer (nullable = true)\n",
            " |-- Experience (in years): integer (nullable = true)\n",
            " |-- Salary (per month - $): integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función para eliminar los valores nulos dentro de la información es *na.drop()*. Esta función elimina completamente los registros que tiene algún valor nulo.\n",
        "\n"
      ],
      "metadata": {
        "id": "KPVY4QKT728z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_null_pyspark.na.drop().show()"
      ],
      "metadata": {
        "id": "Nk7qANkD72Z4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595500bd-7baf-4af2-e846-242e81539e1a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si queremos controlar el como se eliminan los registros la función tiene un parámetro llamado *how* con dos posibles valores:\n",
        "\n",
        "\n",
        "*   ALL: Elimina la tupla siempre y cuando todos los valores asociados a cada columna sean nulos.\n",
        "*   ANY: Elimina la tupla si alguno de los valores asociados a cada columns es nulo. Esta es la configuración por default.\n",
        "\n"
      ],
      "metadata": {
        "id": "HULRD2Mr8WUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_null_pyspark.na.drop(how=\"all\").show()"
      ],
      "metadata": {
        "id": "KI5INUDi9DCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7692bb3c-1d14-469b-9e7f-ada92d750fed"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|        Oscar|           NULL|                 NULL|                 40000|\n",
            "|         NULL|             34|                   10|                 38000|\n",
            "|         NULL|             36|                 NULL|                  NULL|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_null_pyspark.na.drop(how=\"any\").show()"
      ],
      "metadata": {
        "id": "M7EqNcvQ9G02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8531d46d-55ad-43c2-ea6a-a0b5cee8b662"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tambien hay forma de especificar el número mínimo de valores nulos aceptables con el parámetro *thresh*. En el ejemplo se puede observar que elimina solo una tupla que tenia tres valores nulos asociados."
      ],
      "metadata": {
        "id": "6-m7EXqo9L8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_null_pyspark.na.drop(thresh=2).show()"
      ],
      "metadata": {
        "id": "QEZfXpS49XDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ed2421-45f8-43da-b710-191d3e33ffe8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|        Oscar|           NULL|                 NULL|                 40000|\n",
            "|         NULL|             34|                   10|                 38000|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De igual forma podemos cambiar el parámetro *how* con *subset* para indicarle las columnas donde nos interesan detectar valores nulos en las tuplas y eliminarlas."
      ],
      "metadata": {
        "id": "HKMI4Qmc9yji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_null_pyspark.na.drop(how='any', subset=['Experience (in years)']).show()"
      ],
      "metadata": {
        "id": "lhma9LrN9ya0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595a1552-83f1-49e0-8b50-039c5a9e05dc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|         NULL|             34|                   10|                 38000|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos rellenar los valores nulos con algún valor en especifico utilizando la función *na.fill()* indicando el valor y la columna."
      ],
      "metadata": {
        "id": "SKkz--0i-Oyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_null_pyspark.na.fill('LT NA values', 'Employee Name').show()"
      ],
      "metadata": {
        "id": "IAMqYGjo-krE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66805c68-fe92-4fca-bd6f-58b6a3301c2c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+---------------------+----------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "|       Oliver|             31|                   10|                 30000|\n",
            "|        Harry|             30|                    8|                 25000|\n",
            "|       George|             29|                    4|                 20000|\n",
            "|         Jack|             24|                    3|                 20000|\n",
            "|        Jacob|             21|                    1|                 15000|\n",
            "|          Leo|             23|                    2|                 18000|\n",
            "|        Oscar|           NULL|                 NULL|                 40000|\n",
            "| LT NA values|             34|                   10|                 38000|\n",
            "| LT NA values|             36|                 NULL|                  NULL|\n",
            "+-------------+---------------+---------------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra alternativa para rellenar los valores faltantes es utilizando el método de imputación de datos utilizando la media. Para esto hay que utilizar la clase *Imputer* especificando las columnas de entrada y las de salida que se agregaran al DataFrame así como la estrategia en este caso utilizar la media. Después, se utiliza la función *fit()* y *transform()* para integrar las columnas imputadas."
      ],
      "metadata": {
        "id": "GbXa3gu6-u4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols = ['Age of Employee', 'Experience (in years)', 'Salary (per month - $)'],\n",
        "    outputCols = [\"{}_imputed\".format(a) for a in ['Age of Employee', 'Experience (in years)', 'Salary (per month - $)']]\n",
        ").setStrategy(\"mean\")\n",
        "imputer.fit(df_null_pyspark).transform(df_null_pyspark).show()\n"
      ],
      "metadata": {
        "id": "8FAlh9Sy-vBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d9fc0e0-87ad-402d-89aa-0ca87060247e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+---------------------+----------------------+-----------------------+-----------------------------+------------------------------+\n",
            "|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|Age of Employee_imputed|Experience (in years)_imputed|Salary (per month - $)_imputed|\n",
            "+-------------+---------------+---------------------+----------------------+-----------------------+-----------------------------+------------------------------+\n",
            "|       Oliver|             31|                   10|                 30000|                     31|                           10|                         30000|\n",
            "|        Harry|             30|                    8|                 25000|                     30|                            8|                         25000|\n",
            "|       George|             29|                    4|                 20000|                     29|                            4|                         20000|\n",
            "|         Jack|             24|                    3|                 20000|                     24|                            3|                         20000|\n",
            "|        Jacob|             21|                    1|                 15000|                     21|                            1|                         15000|\n",
            "|          Leo|             23|                    2|                 18000|                     23|                            2|                         18000|\n",
            "|        Oscar|           NULL|                 NULL|                 40000|                     28|                            5|                         40000|\n",
            "|         NULL|             34|                   10|                 38000|                     34|                           10|                         38000|\n",
            "|         NULL|             36|                 NULL|                  NULL|                     36|                            5|                         25750|\n",
            "+-------------+---------------+---------------------+----------------------+-----------------------+-----------------------------+------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 4: Manejo de DataFrames en PySpark"
      ],
      "metadata": {
        "id": "7_zMjiAbClef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creamos la sesión de trabajo\n",
        "from pyspark.sql import SparkSession\n",
        "data_spark = SparkSession.builder.appName('DataFrame_article').getOrCreate()\n",
        "data_spark"
      ],
      "metadata": {
        "id": "gWBdsz42Czua",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a79036ef-4239-46b1-e5ba-04565b6e4387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f55143782d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0bd152a0a3aa:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark_LuisTrejo1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos los datos e imprimimos la descripción del schema\n",
        "df_pyspark = data_spark.read.option('header','true').csv('/content/sample_data/california_housing_train.csv', inferSchema=True)\n",
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "id": "4I1c0TjrC9Sv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73de5e6f-8e17-4357-a1db-7da12fd539e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizamos la información\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "id": "d5q5LqAcMVM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "838303d7-9aaf-493d-988a-d96d69907d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|\n",
            "|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|\n",
            "|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|\n",
            "|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n",
            "|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n",
            "|   -114.6|   33.62|              16.0|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|\n",
            "|   -114.6|    33.6|              21.0|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|\n",
            "|  -114.61|   34.84|              48.0|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|\n",
            "|  -114.61|   34.83|              31.0|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|\n",
            "|  -114.63|   32.76|              15.0|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|\n",
            "|  -114.65|   34.89|              17.0|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|\n",
            "|  -114.65|    33.6|              28.0|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|\n",
            "|  -114.65|   32.79|              21.0|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|\n",
            "|  -114.66|   32.74|              17.0|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|\n",
            "|  -114.67|   33.92|              17.0|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En caso de querer cambiar el tipo de dato de alguna columna lo podemos hacer con las funciones *withColumn()* y *cast()*."
      ],
      "metadata": {
        "id": "WSz7YI4wMscN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import column\n",
        "df_pyspark=df_pyspark.withColumn(\"housing_median_age\",column(\"housing_median_age\").cast(\"int\"))"
      ],
      "metadata": {
        "id": "XWt7j0x4MslB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con el atributo *dtypes* podemos saber el tipo de dato por columna"
      ],
      "metadata": {
        "id": "_Oubrma8MEU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.dtypes"
      ],
      "metadata": {
        "id": "5QJEKDVHDHrE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad7ec212-f7e1-4cf5-8ffb-a8ab438a39c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('longitude', 'double'),\n",
              " ('latitude', 'double'),\n",
              " ('housing_median_age', 'int'),\n",
              " ('total_rooms', 'double'),\n",
              " ('total_bedrooms', 'double'),\n",
              " ('population', 'double'),\n",
              " ('households', 'double'),\n",
              " ('median_income', 'double'),\n",
              " ('median_house_value', 'double')]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si queremos saber el nombre de las columnas utilizamos el atributo *columns*"
      ],
      "metadata": {
        "id": "ghry7pbYN43p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.columns"
      ],
      "metadata": {
        "id": "-RjGvsq_DT4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cd49476-b581-4c51-80cf-51f2a48793f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['longitude',\n",
              " 'latitude',\n",
              " 'housing_median_age',\n",
              " 'total_rooms',\n",
              " 'total_bedrooms',\n",
              " 'population',\n",
              " 'households',\n",
              " 'median_income',\n",
              " 'median_house_value']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "También, se puede seleccionar todos los datos de una columna en particular con la función *select()*."
      ],
      "metadata": {
        "id": "YdcYuuXAOBr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select('total_rooms').show()"
      ],
      "metadata": {
        "id": "9k3Qp6F9DWVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "701dd4f6-9f3d-439a-db8f-a801df3efa26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|total_rooms|\n",
            "+-----------+\n",
            "|     5612.0|\n",
            "|     7650.0|\n",
            "|      720.0|\n",
            "|     1501.0|\n",
            "|     1454.0|\n",
            "|     1387.0|\n",
            "|     2907.0|\n",
            "|      812.0|\n",
            "|     4789.0|\n",
            "|     1497.0|\n",
            "|     3741.0|\n",
            "|     1988.0|\n",
            "|     1291.0|\n",
            "|     2478.0|\n",
            "|     1448.0|\n",
            "|     2556.0|\n",
            "|     1678.0|\n",
            "|       44.0|\n",
            "|     1388.0|\n",
            "|       97.0|\n",
            "+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O en caso de querer seleccionar varias columnas tambien se puede lograr enviando una lista con el nombre de las columnas como parámetro."
      ],
      "metadata": {
        "id": "q5T8sf9yOUxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select(['total_rooms', 'total_bedrooms', 'median_income']).show()"
      ],
      "metadata": {
        "id": "_JpH1i60DZVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10b6022e-955a-49f3-8d30-5390dc62473e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+-------------+\n",
            "|total_rooms|total_bedrooms|median_income|\n",
            "+-----------+--------------+-------------+\n",
            "|     5612.0|        1283.0|       1.4936|\n",
            "|     7650.0|        1901.0|         1.82|\n",
            "|      720.0|         174.0|       1.6509|\n",
            "|     1501.0|         337.0|       3.1917|\n",
            "|     1454.0|         326.0|        1.925|\n",
            "|     1387.0|         236.0|       3.3438|\n",
            "|     2907.0|         680.0|       2.6768|\n",
            "|      812.0|         168.0|       1.7083|\n",
            "|     4789.0|        1175.0|       2.1782|\n",
            "|     1497.0|         309.0|       2.1908|\n",
            "|     3741.0|         801.0|       2.6797|\n",
            "|     1988.0|         483.0|        1.625|\n",
            "|     1291.0|         248.0|       2.1571|\n",
            "|     2478.0|         464.0|        3.212|\n",
            "|     1448.0|         378.0|       0.8585|\n",
            "|     2556.0|         587.0|       1.6991|\n",
            "|     1678.0|         322.0|       2.9653|\n",
            "|       44.0|          33.0|       0.8571|\n",
            "|     1388.0|         386.0|       1.2049|\n",
            "|       97.0|          24.0|       1.2656|\n",
            "+-----------+--------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si queremos saber algunas medidas de tendencia central de los datos para los análisis estadísticos se puede utilizar la función *describe()* similar a Pandas."
      ],
      "metadata": {
        "id": "y3KgSo5MOg6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.describe().show()"
      ],
      "metadata": {
        "id": "xfKnLrhzDbua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca4ac95-4fcf-49a2-fccb-600bed8e2eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "|summary|          longitude|          latitude|housing_median_age|      total_rooms|   total_bedrooms|        population|       households|     median_income|median_house_value|\n",
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "|  count|              17000|             17000|             17000|            17000|            17000|             17000|            17000|             17000|             17000|\n",
            "|   mean|-119.56210823529375|  35.6252247058827| 28.58935294117647|2643.664411764706|539.4108235294118|1429.5739411764705|501.2219411764706| 3.883578100000021|207300.91235294117|\n",
            "| stddev| 2.0051664084260357|2.1373397946570867|12.586936981660406|2179.947071452777|421.4994515798648| 1147.852959159527|384.5208408559016|1.9081565183791036|115983.76438720895|\n",
            "|    min|            -124.35|             32.54|                 1|              2.0|              1.0|               3.0|              1.0|            0.4999|           14999.0|\n",
            "|    max|            -114.31|             41.95|                52|          37937.0|           6445.0|           35682.0|           6082.0|           15.0001|          500001.0|\n",
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De igual manera se pueden agregar columnas directamente al DataFrame si se requiere."
      ],
      "metadata": {
        "id": "eE5gL9snPdsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = df_pyspark.withColumn('Updated_medianhousevalue', df_pyspark['median_house_value']*2)\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "id": "t38O8t0cDfY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c0a1e3-d969-4f84-e9de-efd058cfa44b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|Updated_medianhousevalue|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------------------------+\n",
            "|  -114.31|   34.19|                15|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|                133800.0|\n",
            "|  -114.47|    34.4|                19|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|                160200.0|\n",
            "|  -114.56|   33.69|                17|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|                171400.0|\n",
            "|  -114.57|   33.64|                14|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|                146800.0|\n",
            "|  -114.57|   33.57|                20|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|                131000.0|\n",
            "|  -114.58|   33.63|                29|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|                148000.0|\n",
            "|  -114.58|   33.61|                25|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|                164800.0|\n",
            "|  -114.59|   34.83|                41|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|                 97000.0|\n",
            "|  -114.59|   33.61|                34|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|                116800.0|\n",
            "|   -114.6|   34.83|                46|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|                 96200.0|\n",
            "|   -114.6|   33.62|                16|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|                173000.0|\n",
            "|   -114.6|    33.6|                21|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|                124000.0|\n",
            "|  -114.61|   34.84|                48|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|                 97200.0|\n",
            "|  -114.61|   34.83|                31|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|                140800.0|\n",
            "|  -114.63|   32.76|                15|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|                 90000.0|\n",
            "|  -114.65|   34.89|                17|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|                138200.0|\n",
            "|  -114.65|    33.6|                28|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|                189800.0|\n",
            "|  -114.65|   32.79|                21|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|                 50000.0|\n",
            "|  -114.66|   32.74|                17|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|                 88000.0|\n",
            "|  -114.67|   33.92|                17|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|                 55000.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De igual forma se pueden eliminar con la función *drop()*"
      ],
      "metadata": {
        "id": "VHB46MbDPnmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.drop('Updated_medianhousevalue').show()"
      ],
      "metadata": {
        "id": "F5Vp00etD_LX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67310cd7-85c9-41c7-d9da-04adbd489016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|                15|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|                19|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|                17|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|                14|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|                20|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "|  -114.58|   33.63|                29|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|\n",
            "|  -114.58|   33.61|                25|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|\n",
            "|  -114.59|   34.83|                41|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|\n",
            "|  -114.59|   33.61|                34|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n",
            "|   -114.6|   34.83|                46|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n",
            "|   -114.6|   33.62|                16|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|\n",
            "|   -114.6|    33.6|                21|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|\n",
            "|  -114.61|   34.84|                48|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|\n",
            "|  -114.61|   34.83|                31|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|\n",
            "|  -114.63|   32.76|                15|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|\n",
            "|  -114.65|   34.89|                17|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|\n",
            "|  -114.65|    33.6|                28|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|\n",
            "|  -114.65|   32.79|                21|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|\n",
            "|  -114.66|   32.74|                17|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|\n",
            "|  -114.67|   33.92|                17|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 5: Agregación y agrupamientos\n",
        "\n",
        "Agrupar los datos es una de las habilidades más esenciales cuando trabajamos con Big Data dado que estamos tratando con una gran cantidad de datos y si no somos capaces de segmentar esos datos, entonces será mucho más difícil analizarlos y usarlos para obtener información relevante\n",
        "\n",
        "La regla de oro es recordar que la función *groupBy()* y la función de agregación van de la mano, es decir, no podemos usar groupBy sin la función agregada como SUM, COUNT, AVG, MAX, MIN, etc."
      ],
      "metadata": {
        "id": "cYc2mWGlPxFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark_aggregate = SparkSession.builder.appName('Aggregate and GroupBy').getOrCreate()\n",
        "spark_aggregate"
      ],
      "metadata": {
        "id": "pCMVYeyoT0dq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e94d4fe5-c6d8-47b9-87fa-9638da1eb058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f55143782d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0bd152a0a3aa:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark_LuisTrejo1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark_aggregate_data = spark_aggregate.read.csv('part4.csv', header = True, inferSchema = True)\n",
        "spark_aggregate_data.show()\n"
      ],
      "metadata": {
        "id": "L8YpcNuaTtUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db2ec75-607d-4b26-dcd3-cbb934ccc6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+------+\n",
            "|  Name|  Departmens|salary|\n",
            "+------+------------+------+\n",
            "|Oliver|Data Science| 10000|\n",
            "|Oliver|         IOT|  5000|\n",
            "| Johny|    Big Data|  4000|\n",
            "|Oliver|    Big Data|  4000|\n",
            "| Johny|Data Science|  3000|\n",
            "|Mathew|Data Science| 20000|\n",
            "|Mathew|         IOT| 10000|\n",
            "|Mathew|    Big Data|  5000|\n",
            "| Jacob|Data Science| 10000|\n",
            "| Jacob|    Big Data|  2000|\n",
            "+------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si llegamos a ejecutar unicamente la función *groupBy()* la respuesta será la ubicación de los datos agrupados lo cual no es relevante"
      ],
      "metadata": {
        "id": "j74wnJlET8Gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_aggregate_data.groupBy('Name')"
      ],
      "metadata": {
        "id": "R9mnirSyS6O5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff494b25-4b69-44ea-dc4b-c2cef27d10b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.group.GroupedData at 0x7f5510f6a290>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funciones de agregación\n",
        "\n",
        "Algunas de las funciones más comunes son:\n",
        "\n",
        "\n",
        "\n",
        "*   AVG: devuelve el conjunto de resultados agrupando la columna según el promedio del conjunto de valores.\n",
        "*   COUNT: devolverá el número total de conjuntos de valores en una columna particular correspondiente a la función groupBy.\n",
        "*   MIN: devuelve el valor mínimo o más pequeño entre todo el conjunto de valores en toda la fila.\n",
        "*   MAX: el funcionamiento y el enfoque de usar la función agregada MAX es el mismo que la función agregada MIN, solo que la principal diferencia es que devolverá el valor máximo entre el conjunto de valores en la fila.\n",
        "*   SUM: devolverá la suma de todos los valores numéricos correspondientes a la columna agrupada\n",
        "\n"
      ],
      "metadata": {
        "id": "AAlB-sLiUZGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si ejecutamos la función de agrupamiento y agregación el resultado será la descripción del DataFrame por lo que si queremos visualizar la información hay que utilizar la función *show()*."
      ],
      "metadata": {
        "id": "KGaco-YtWYNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_aggregate_data.groupBy('Name').sum()"
      ],
      "metadata": {
        "id": "y-35ZH9tVBHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e69f727-90d9-4ed0-fa96-031817ef1aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, sum(salary): bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo: Conocer la cantidad de dinero total que le pago la compañia a cada empleado agrupando por nombre"
      ],
      "metadata": {
        "id": "q54ThS92XAqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_aggregate_data.groupBy('Name').sum().show()"
      ],
      "metadata": {
        "id": "AHDQqxfGW0PD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a5662bb-72e4-48b2-b383-f7817c2ccfee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+\n",
            "|  Name|sum(salary)|\n",
            "+------+-----------+\n",
            "| Jacob|      12000|\n",
            "| Johny|       7000|\n",
            "|Mathew|      35000|\n",
            "|Oliver|      19000|\n",
            "+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo: Conocer la cantidad de dinero total que pago cada departamento a sus empleados"
      ],
      "metadata": {
        "id": "qyyW7WWZXHx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_aggregate_data.groupBy('Departmens').sum().show()"
      ],
      "metadata": {
        "id": "c5st2YW3XPIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba9914d9-295f-445c-fd19-c15c09231e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "|  Departmens|sum(salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|      15000|\n",
            "|    Big Data|      15000|\n",
            "|Data Science|      43000|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo: Conocer el salario promedio que se le pago a los empleados por departamento"
      ],
      "metadata": {
        "id": "3imE2OXvXaIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_aggregate_data.groupBy('Departmens').mean().show()"
      ],
      "metadata": {
        "id": "EdtCu_hsXnO5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4c7111-b539-4b26-99a3-38ce1b688e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "|  Departmens|avg(salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|     7500.0|\n",
            "|    Big Data|     3750.0|\n",
            "|Data Science|    10750.0|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo: Saber el número de pagos que recibio cada empleado"
      ],
      "metadata": {
        "id": "MlhwGhpkXylB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_aggregate_data.groupBy(['Name']).count().show()"
      ],
      "metadata": {
        "id": "oEowM03EXywJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a7169d3-5f61-46e2-c844-cbcad7fcdb51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|  Name|count|\n",
            "+------+-----+\n",
            "| Jacob|    2|\n",
            "| Johny|    2|\n",
            "|Mathew|    3|\n",
            "|Oliver|    3|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark_aggregate_data.groupBy('Name').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9pddSi7WG57",
        "outputId": "fe99ab6f-df0f-43a5-eb2e-6306bc96a9bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|  Name|count|\n",
            "+------+-----+\n",
            "| Jacob|    2|\n",
            "| Johny|    2|\n",
            "|Mathew|    3|\n",
            "|Oliver|    3|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracción de valores numércios\n",
        "Referencia\n",
        "https://www.geeksforgeeks.org/get-value-of-a-particular-cell-in-pyspark-dataframe/"
      ],
      "metadata": {
        "id": "fp8fPy5Ot-vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_aggregate_data.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45Te74Cxt9n_",
        "outputId": "bf900295-7408-4d14-a420-a3c614d7e3e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+------+\n",
            "|  Name|  Departmens|salary|\n",
            "+------+------------+------+\n",
            "|Oliver|Data Science| 10000|\n",
            "|Oliver|         IOT|  5000|\n",
            "| Johny|    Big Data|  4000|\n",
            "|Oliver|    Big Data|  4000|\n",
            "| Johny|Data Science|  3000|\n",
            "|Mathew|Data Science| 20000|\n",
            "|Mathew|         IOT| 10000|\n",
            "|Mathew|    Big Data|  5000|\n",
            "| Jacob|Data Science| 10000|\n",
            "| Jacob|    Big Data|  2000|\n",
            "+------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraer el primer renglón"
      ],
      "metadata": {
        "id": "uDC1E2qSvAgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_aggregate_data.collect()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1QCsdBXvFu8",
        "outputId": "884e5ed6-c0cc-4c8e-c58f-89c08b66dfb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(Name='Oliver', Departmens='Data Science', salary=10000)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extarer su Salario"
      ],
      "metadata": {
        "id": "o3eryxy-vI2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Salario = spark_aggregate_data.collect()[0][2]\n",
        "Salario\n",
        "Salario = Salario * 1.5\n",
        "Salario"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcO3w6PMvLfE",
        "outputId": "09c5649a-2359-4ec1-8cab-9ae446a5c7d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15000.0"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 6: Usando ML en PySpark"
      ],
      "metadata": {
        "id": "MHhiL2rneKF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "df_ml = SparkSession.builder.appName('EjemploML').getOrCreate()\n",
        "df_ml"
      ],
      "metadata": {
        "id": "lzkltL3aeXm-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "e334c41b-dafd-4852-fb9b-64db5bbb5d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f6a7ca40310>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://60ace41a9e26:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>EjemploML</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos la información en un DataFrame\n",
        "training_dataset  = df_ml.read.csv('UserCarDataExample.csv', header=True, inferSchema=True)\n",
        "training_dataset"
      ],
      "metadata": {
        "id": "tumrUfnSf8z4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf70a46d-b714-4f46-d297-073179f56709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[age: int, selling_price: int, km_driven: int, mileage: double, engine: int, max_power: double, seats: int]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostramos la información\n",
        "training_dataset.show()"
      ],
      "metadata": {
        "id": "Kb1J2b66gLEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca9d1ab-0047-40da-830d-eb0125081634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------+---------+-------+------+---------+-----+\n",
            "|age|selling_price|km_driven|mileage|engine|max_power|seats|\n",
            "+---+-------------+---------+-------+------+---------+-----+\n",
            "|  8|       450000|   145500|   23.4|  1248|     74.0|    5|\n",
            "|  8|       370000|   120000|  21.14|  1498|   103.52|    5|\n",
            "| 16|       158000|   140000|   17.7|  1497|     78.0|    5|\n",
            "| 12|       225000|   127000|   23.0|  1396|     90.0|    5|\n",
            "| 15|       130000|   120000|   16.1|  1298|     88.2|    5|\n",
            "|  5|       440000|    45000|  20.14|  1197|    81.86|    5|\n",
            "| 15|        96000|   175000|   17.3|  1061|     57.5|    5|\n",
            "| 21|        45000|     5000|   16.1|   796|     37.0|    4|\n",
            "| 11|       350000|    90000|  23.59|  1364|     67.1|    5|\n",
            "|  9|       200000|   169000|   20.0|  1399|     68.1|    5|\n",
            "|  8|       500000|    68000|  19.01|  1461|   108.45|    5|\n",
            "| 17|        92000|   100000|   17.3|   993|     60.0|    5|\n",
            "| 13|       280000|   140000|   19.3|  1248|     73.9|    5|\n",
            "| 13|       180000|    90000|   18.9|  1061|     67.0|    5|\n",
            "|  6|       400000|    40000|  18.15|  1198|     82.0|    5|\n",
            "|  6|       778000|    70000|  24.52|  1248|     88.5|    7|\n",
            "| 10|       500000|    53000|   23.0|  1396|     90.0|    5|\n",
            "| 20|       150000|    80000|   19.7|   796|     46.3|    5|\n",
            "|  6|       680000|   100000|  22.54|  1396|    88.73|    5|\n",
            "| 11|       174000|   100000|   21.0|  1461|     64.1|    5|\n",
            "+---+-------------+---------+-------+------+---------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizamos el esquema de la base de datos\n",
        "training_dataset.printSchema()"
      ],
      "metadata": {
        "id": "0H4E0wYKgOnS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0fdbf5f-ba5d-43e8-af49-f4a6d1896fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- selling_price: integer (nullable = true)\n",
            " |-- km_driven: integer (nullable = true)\n",
            " |-- mileage: double (nullable = true)\n",
            " |-- engine: integer (nullable = true)\n",
            " |-- max_power: double (nullable = true)\n",
            " |-- seats: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizamos el nombre de las columnas\n",
        "training_dataset.columns"
      ],
      "metadata": {
        "id": "QQkaCFvAgRL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84bce780-5d01-4715-b140-bc1a7a24c684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age',\n",
              " 'selling_price',\n",
              " 'km_driven',\n",
              " 'mileage',\n",
              " 'engine',\n",
              " 'max_power',\n",
              " 'seats']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para trabajar con modelos de regresión tenemos que utilizar *VectorAssembler* para convertir las variables independientes en un vector que las incluya"
      ],
      "metadata": {
        "id": "moU5VyLK8tlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "featassembler = VectorAssembler(inputCols=['age',\n",
        " 'km_driven',\n",
        " 'mileage',\n",
        " 'engine',\n",
        " 'max_power',\n",
        " 'seats'], outputCol = \"Independent Features\" )\n",
        "featassembler"
      ],
      "metadata": {
        "id": "bw-DruM-gkRm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e893910e-0111-4c02-d7a6-900ceb4d753e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorAssembler_bf6225cdeb5d"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Posteriormente se integran al conjunto de datos que ya estaba cargado utilizando la función *transform()*."
      ],
      "metadata": {
        "id": "-j2BdYSb9LCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = featassembler.transform(training_dataset)\n",
        "result.show()"
      ],
      "metadata": {
        "id": "aSF0ijSFgsqS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab797cfb-2ed7-4be8-a423-c8e609c3cb3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------+---------+-------+------+---------+-----+--------------------+\n",
            "|age|selling_price|km_driven|mileage|engine|max_power|seats|Independent Features|\n",
            "+---+-------------+---------+-------+------+---------+-----+--------------------+\n",
            "|  8|       450000|   145500|   23.4|  1248|     74.0|    5|[8.0,145500.0,23....|\n",
            "|  8|       370000|   120000|  21.14|  1498|   103.52|    5|[8.0,120000.0,21....|\n",
            "| 16|       158000|   140000|   17.7|  1497|     78.0|    5|[16.0,140000.0,17...|\n",
            "| 12|       225000|   127000|   23.0|  1396|     90.0|    5|[12.0,127000.0,23...|\n",
            "| 15|       130000|   120000|   16.1|  1298|     88.2|    5|[15.0,120000.0,16...|\n",
            "|  5|       440000|    45000|  20.14|  1197|    81.86|    5|[5.0,45000.0,20.1...|\n",
            "| 15|        96000|   175000|   17.3|  1061|     57.5|    5|[15.0,175000.0,17...|\n",
            "| 21|        45000|     5000|   16.1|   796|     37.0|    4|[21.0,5000.0,16.1...|\n",
            "| 11|       350000|    90000|  23.59|  1364|     67.1|    5|[11.0,90000.0,23....|\n",
            "|  9|       200000|   169000|   20.0|  1399|     68.1|    5|[9.0,169000.0,20....|\n",
            "|  8|       500000|    68000|  19.01|  1461|   108.45|    5|[8.0,68000.0,19.0...|\n",
            "| 17|        92000|   100000|   17.3|   993|     60.0|    5|[17.0,100000.0,17...|\n",
            "| 13|       280000|   140000|   19.3|  1248|     73.9|    5|[13.0,140000.0,19...|\n",
            "| 13|       180000|    90000|   18.9|  1061|     67.0|    5|[13.0,90000.0,18....|\n",
            "|  6|       400000|    40000|  18.15|  1198|     82.0|    5|[6.0,40000.0,18.1...|\n",
            "|  6|       778000|    70000|  24.52|  1248|     88.5|    7|[6.0,70000.0,24.5...|\n",
            "| 10|       500000|    53000|   23.0|  1396|     90.0|    5|[10.0,53000.0,23....|\n",
            "| 20|       150000|    80000|   19.7|   796|     46.3|    5|[20.0,80000.0,19....|\n",
            "|  6|       680000|   100000|  22.54|  1396|    88.73|    5|[6.0,100000.0,22....|\n",
            "| 11|       174000|   100000|   21.0|  1461|     64.1|    5|[11.0,100000.0,21...|\n",
            "+---+-------------+---------+-------+------+---------+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para construir nuestro modelo de regresión debemos selecccionar la columna que integró los valores de las columnas en un vector y la columna que representa la variable dependiente."
      ],
      "metadata": {
        "id": "rEIplNaj9aTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = result.select(\"Independent features\", \"selling_price\")\n",
        "final_data.show()"
      ],
      "metadata": {
        "id": "AkN24b3_gxBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e14e299-5bec-483d-b474-1d75531aa47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------+\n",
            "|Independent features|selling_price|\n",
            "+--------------------+-------------+\n",
            "|[8.0,145500.0,23....|       450000|\n",
            "|[8.0,120000.0,21....|       370000|\n",
            "|[16.0,140000.0,17...|       158000|\n",
            "|[12.0,127000.0,23...|       225000|\n",
            "|[15.0,120000.0,16...|       130000|\n",
            "|[5.0,45000.0,20.1...|       440000|\n",
            "|[15.0,175000.0,17...|        96000|\n",
            "|[21.0,5000.0,16.1...|        45000|\n",
            "|[11.0,90000.0,23....|       350000|\n",
            "|[9.0,169000.0,20....|       200000|\n",
            "|[8.0,68000.0,19.0...|       500000|\n",
            "|[17.0,100000.0,17...|        92000|\n",
            "|[13.0,140000.0,19...|       280000|\n",
            "|[13.0,90000.0,18....|       180000|\n",
            "|[6.0,40000.0,18.1...|       400000|\n",
            "|[6.0,70000.0,24.5...|       778000|\n",
            "|[10.0,53000.0,23....|       500000|\n",
            "|[20.0,80000.0,19....|       150000|\n",
            "|[6.0,100000.0,22....|       680000|\n",
            "|[11.0,100000.0,21...|       174000|\n",
            "+--------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Del conjunto total de datos se puede generar un división de conjunto de datos entre entrenamiento y prueba con la función *randomSplit*."
      ],
      "metadata": {
        "id": "PXw3mdLr-ieZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = final_data.randomSplit([0.75, 0.25])"
      ],
      "metadata": {
        "id": "iRqfuLCSg3WF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora bien hay que importar *LinearRegression* de la biblioteca de machine learning de PySpark. Especificando cuales son la variables independientes y cual es la dependiente."
      ],
      "metadata": {
        "id": "1enV5l9G-ul7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "model = LinearRegression(featuresCol = 'Independent features', labelCol='selling_price')\n",
        "model = model.fit(train_data)"
      ],
      "metadata": {
        "id": "XzyfNi_5g6Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos imprimir la matriz de correlación para verificar la congruencia del modelo."
      ],
      "metadata": {
        "id": "hWZ7qUpPANhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.stat import Correlation\n",
        "\n",
        "matrix = Correlation.corr(final_data, 'Independent features')\n",
        "cor_np = matrix.collect()[0][matrix.columns[0]].toArray()\n",
        "cor_np"
      ],
      "metadata": {
        "id": "q_PZNczQjDUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dd85152-0244-410d-8a19-77e376d82703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.2.2-bin-hadoop3.2/python/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        ,  0.42854848, -0.32854385, -0.0182631 , -0.2265978 ,\n",
              "         0.00792303],\n",
              "       [ 0.42854848,  1.        , -0.17298035,  0.20603073, -0.03815852,\n",
              "         0.22725939],\n",
              "       [-0.32854385, -0.17298035,  1.        , -0.57640787, -0.37462089,\n",
              "        -0.45170047],\n",
              "       [-0.0182631 ,  0.20603073, -0.57640787,  1.        ,  0.70397453,\n",
              "         0.61110339],\n",
              "       [-0.2265978 , -0.03815852, -0.37462089,  0.70397453,  1.        ,\n",
              "         0.19199918],\n",
              "       [ 0.00792303,  0.22725939, -0.45170047,  0.61110339,  0.19199918,\n",
              "         1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtener el valor del intercepto."
      ],
      "metadata": {
        "id": "K0eiZUdrAUKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.intercept"
      ],
      "metadata": {
        "id": "hRPAwuMDhGsQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b04f0173-cd73-4dcd-bea9-ddde873ebcfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-173769.9227155356"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los coeficientes por cada variable independiente"
      ],
      "metadata": {
        "id": "LWm_ACuzAXhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.coefficients"
      ],
      "metadata": {
        "id": "RmOSQXazhC4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b23173a5-93cc-4bbc-95d1-16c0b9dda888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseVector([-44971.9493, -1.2105, 6639.738, 108.4468, 15387.114, -78662.7525])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Así como los p-values para determinar la transendencia de cada variable dentro del modelo."
      ],
      "metadata": {
        "id": "SvVYUVYQAbst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary.pValues"
      ],
      "metadata": {
        "id": "DvpGrjq1iEvM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a333c8b6-118e-431d-e408-9eb86275e259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0,\n",
              " 0.0,\n",
              " 0.002742261743691632,\n",
              " 3.523048235209991e-05,\n",
              " 0.0,\n",
              " 6.661338147750939e-16,\n",
              " 0.04900845799491815]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtener indicadores de desempeño como la $r^2$ ajustada, dado que es un problema multivariado. Que nos sirve para indicar el porcentaje de la variabilidad de la variable dependiente explicada por el modelo."
      ],
      "metadata": {
        "id": "bz0Mb-N_AkKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary.r2adj"
      ],
      "metadata": {
        "id": "Pi-wb7QUifex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a3f3ae-3e80-4c3b-a7f0-1bc48de35f68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6321404714030512"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos realizar predicciones para evaluar el modelo obtenido."
      ],
      "metadata": {
        "id": "g5rpjApHA12V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_result = model.evaluate(test_data)\n",
        "prediction_result.predictions.show()"
      ],
      "metadata": {
        "id": "gHIihH1RhJ-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90df7fbc-d63f-467d-96fa-92adff1aa315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------+------------------+\n",
            "|Independent features|selling_price|        prediction|\n",
            "+--------------------+-------------+------------------+\n",
            "|[2.0,1000.0,20.3,...|       500000| 641722.6632724255|\n",
            "|[2.0,1000.0,21.21...|       445000| 871067.4907851031|\n",
            "|[2.0,1600.0,13.96...|      1900000|1760665.7369542336|\n",
            "|[2.0,2136.0,22.5,...|       350000| 629055.9157200744|\n",
            "|[2.0,5000.0,0.0,2...|       679000| 923617.4918622139|\n",
            "|[2.0,5000.0,21.01...|       630000| 864897.6729820727|\n",
            "|[2.0,5000.0,21.21...|       570000| 866225.6205875105|\n",
            "|[2.0,5000.0,21.21...|       600000| 866225.6205875105|\n",
            "|[2.0,5500.0,26.8,...|      2125000|1503128.7539815935|\n",
            "|[2.0,10000.0,18.7...|       737000| 1202851.782968651|\n",
            "|[2.0,10000.0,19.0...|       450000| 618780.7713926989|\n",
            "|[2.0,15000.0,23.2...|       550000| 970826.0720435185|\n",
            "|[2.0,15000.0,24.3...|       810000| 983262.1843195695|\n",
            "|[2.0,20000.0,23.2...|       700000| 964773.7342965277|\n",
            "|[2.0,40000.0,10.7...|      1500000| 1940968.776891451|\n",
            "|[2.0,40000.0,17.5...|       500000| 905427.9097021874|\n",
            "|[2.0,44665.0,25.3...|       480000| 693089.2954687983|\n",
            "|[2.0,50000.0,20.1...|       260000| 940386.1997395628|\n",
            "|[2.0,60000.0,25.3...|       550000| 674526.7755987778|\n",
            "|[2.0,120000.0,21....|       250000| 480500.3496347894|\n",
            "+--------------------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostrar algunos indicadores de desempeño utiles."
      ],
      "metadata": {
        "id": "DzBuAmmiA7pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_result.meanAbsoluteError, prediction_result.meanSquaredError"
      ],
      "metadata": {
        "id": "zdRto3yjhe_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecaf071b-9769-4dde-c585-a7657dc5e31d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(288271.49654614413, 225886958021.10565)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.tree import DecisionTree\n",
        "from pyspark.mllib.tree import DecisionTreeModel\n",
        "\n",
        "from pyspark import SparkContext\n",
        "\n",
        "sc = SparkContext.getOrCreate()"
      ],
      "metadata": {
        "id": "qmz6gEjCCGLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.util import MLUtils\n",
        "\n",
        "data = MLUtils.loadLibSVMFile(sc, 'spark-3.2.2-bin-hadoop3.2/data/mllib/sample_libsvm_data.txt')\n"
      ],
      "metadata": {
        "id": "eINQssUpC729"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
      ],
      "metadata": {
        "id": "K_bVJzJ4YDZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.take(10)"
      ],
      "metadata": {
        "id": "Fo4frQjCFH26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd6cf0b6-9e71-4552-ce01-f1f2cd019426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[LabeledPoint(0.0, (692,[127,128,129,130,131,154,155,156,157,158,159,181,182,183,184,185,186,187,188,189,207,208,209,210,211,212,213,214,215,216,217,235,236,237,238,239,240,241,242,243,244,245,262,263,264,265,266,267,268,269,270,271,272,273,289,290,291,292,293,294,295,296,297,300,301,302,316,317,318,319,320,321,328,329,330,343,344,345,346,347,348,349,356,357,358,371,372,373,374,384,385,386,399,400,401,412,413,414,426,427,428,429,440,441,442,454,455,456,457,466,467,468,469,470,482,483,484,493,494,495,496,497,510,511,512,520,521,522,523,538,539,540,547,548,549,550,566,567,568,569,570,571,572,573,574,575,576,577,578,594,595,596,597,598,599,600,601,602,603,604,622,623,624,625,626,627,628,629,630,651,652,653,654,655,656,657],[51.0,159.0,253.0,159.0,50.0,48.0,238.0,252.0,252.0,252.0,237.0,54.0,227.0,253.0,252.0,239.0,233.0,252.0,57.0,6.0,10.0,60.0,224.0,252.0,253.0,252.0,202.0,84.0,252.0,253.0,122.0,163.0,252.0,252.0,252.0,253.0,252.0,252.0,96.0,189.0,253.0,167.0,51.0,238.0,253.0,253.0,190.0,114.0,253.0,228.0,47.0,79.0,255.0,168.0,48.0,238.0,252.0,252.0,179.0,12.0,75.0,121.0,21.0,253.0,243.0,50.0,38.0,165.0,253.0,233.0,208.0,84.0,253.0,252.0,165.0,7.0,178.0,252.0,240.0,71.0,19.0,28.0,253.0,252.0,195.0,57.0,252.0,252.0,63.0,253.0,252.0,195.0,198.0,253.0,190.0,255.0,253.0,196.0,76.0,246.0,252.0,112.0,253.0,252.0,148.0,85.0,252.0,230.0,25.0,7.0,135.0,253.0,186.0,12.0,85.0,252.0,223.0,7.0,131.0,252.0,225.0,71.0,85.0,252.0,145.0,48.0,165.0,252.0,173.0,86.0,253.0,225.0,114.0,238.0,253.0,162.0,85.0,252.0,249.0,146.0,48.0,29.0,85.0,178.0,225.0,253.0,223.0,167.0,56.0,85.0,252.0,252.0,252.0,229.0,215.0,252.0,252.0,252.0,196.0,130.0,28.0,199.0,252.0,252.0,253.0,252.0,252.0,233.0,145.0,25.0,128.0,252.0,253.0,252.0,141.0,37.0])),\n",
              " LabeledPoint(1.0, (692,[158,159,160,161,185,186,187,188,189,213,214,215,216,217,240,241,242,243,244,245,267,268,269,270,271,295,296,297,298,322,323,324,325,326,349,350,351,352,353,377,378,379,380,381,404,405,406,407,408,431,432,433,434,435,459,460,461,462,463,486,487,488,489,490,514,515,516,517,518,542,543,544,545,569,570,571,572,573,596,597,598,599,600,601,624,625,626,627,652,653,654,655,680,681,682,683],[124.0,253.0,255.0,63.0,96.0,244.0,251.0,253.0,62.0,127.0,251.0,251.0,253.0,62.0,68.0,236.0,251.0,211.0,31.0,8.0,60.0,228.0,251.0,251.0,94.0,155.0,253.0,253.0,189.0,20.0,253.0,251.0,235.0,66.0,32.0,205.0,253.0,251.0,126.0,104.0,251.0,253.0,184.0,15.0,80.0,240.0,251.0,193.0,23.0,32.0,253.0,253.0,253.0,159.0,151.0,251.0,251.0,251.0,39.0,48.0,221.0,251.0,251.0,172.0,234.0,251.0,251.0,196.0,12.0,253.0,251.0,251.0,89.0,159.0,255.0,253.0,253.0,31.0,48.0,228.0,253.0,247.0,140.0,8.0,64.0,251.0,253.0,220.0,64.0,251.0,253.0,220.0,24.0,193.0,253.0,220.0])),\n",
              " LabeledPoint(1.0, (692,[124,125,126,127,151,152,153,154,155,179,180,181,182,183,208,209,210,211,235,236,237,238,239,263,264,265,266,267,268,292,293,294,295,296,321,322,323,324,349,350,351,352,377,378,379,380,405,406,407,408,433,434,435,436,461,462,463,464,489,490,491,492,493,517,518,519,520,521,545,546,547,548,549,574,575,576,577,578,602,603,604,605,606,630,631,632,633,634,658,659,660,661,662],[145.0,255.0,211.0,31.0,32.0,237.0,253.0,252.0,71.0,11.0,175.0,253.0,252.0,71.0,144.0,253.0,252.0,71.0,16.0,191.0,253.0,252.0,71.0,26.0,221.0,253.0,252.0,124.0,31.0,125.0,253.0,252.0,252.0,108.0,253.0,252.0,252.0,108.0,255.0,253.0,253.0,108.0,253.0,252.0,252.0,108.0,253.0,252.0,252.0,108.0,253.0,252.0,252.0,108.0,255.0,253.0,253.0,170.0,253.0,252.0,252.0,252.0,42.0,149.0,252.0,252.0,252.0,144.0,109.0,252.0,252.0,252.0,144.0,218.0,253.0,253.0,255.0,35.0,175.0,252.0,252.0,253.0,35.0,73.0,252.0,252.0,253.0,35.0,31.0,211.0,252.0,253.0,35.0])),\n",
              " LabeledPoint(1.0, (692,[152,153,154,180,181,182,183,208,209,210,211,236,237,238,239,264,265,266,267,292,293,294,295,320,321,322,323,349,350,351,377,378,379,405,406,407,433,434,435,461,462,463,489,490,491,492,517,518,519,520,546,547,548,574,575,576,602,603,604,630,631,632,658,659,660,686,687,688],[5.0,63.0,197.0,20.0,254.0,230.0,24.0,20.0,254.0,254.0,48.0,20.0,254.0,255.0,48.0,20.0,254.0,254.0,57.0,20.0,254.0,254.0,108.0,16.0,239.0,254.0,143.0,178.0,254.0,143.0,178.0,254.0,143.0,178.0,254.0,162.0,178.0,254.0,240.0,113.0,254.0,240.0,83.0,254.0,245.0,31.0,79.0,254.0,246.0,38.0,214.0,254.0,150.0,144.0,241.0,8.0,144.0,240.0,2.0,144.0,254.0,82.0,230.0,247.0,40.0,168.0,209.0,31.0])),\n",
              " LabeledPoint(1.0, (692,[151,152,153,154,179,180,181,182,208,209,210,236,237,238,264,265,266,267,292,293,294,295,320,321,322,323,348,349,350,351,376,377,378,379,404,405,406,407,432,433,434,435,460,461,462,463,488,489,490,491,516,517,518,519,544,545,546,547,572,573,574,575,600,601,602,603,629,630,631,657,658,659,685,686,687],[1.0,168.0,242.0,28.0,10.0,228.0,254.0,100.0,190.0,254.0,122.0,83.0,254.0,162.0,29.0,254.0,248.0,25.0,29.0,255.0,254.0,103.0,29.0,254.0,254.0,109.0,29.0,254.0,254.0,109.0,29.0,254.0,254.0,109.0,29.0,255.0,254.0,109.0,29.0,254.0,254.0,109.0,29.0,254.0,254.0,63.0,29.0,254.0,254.0,28.0,29.0,254.0,254.0,28.0,29.0,254.0,254.0,35.0,29.0,254.0,254.0,109.0,6.0,212.0,254.0,109.0,203.0,254.0,178.0,155.0,254.0,190.0,32.0,199.0,104.0])),\n",
              " LabeledPoint(0.0, (692,[129,130,131,132,156,157,158,159,160,161,162,183,184,185,186,187,188,189,190,208,209,210,211,212,213,214,215,216,217,218,235,236,237,238,239,240,241,242,243,244,245,246,262,263,264,265,266,267,268,269,270,271,272,273,274,289,290,291,292,293,294,295,296,297,298,299,300,301,302,316,317,318,319,320,322,323,324,325,327,328,329,330,343,344,345,346,347,348,350,351,352,353,355,356,357,358,371,372,373,374,378,379,384,385,386,398,399,400,412,413,414,425,426,427,428,439,440,441,442,453,454,455,456,467,468,469,470,481,482,483,484,494,495,496,497,498,509,510,511,512,521,522,523,524,525,537,538,539,540,547,548,549,550,551,552,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,594,595,596,597,598,599,600,601,602,603,604,605,623,624,625,626,627,628,629,630,631,632,653,654,655,656,657,658],[64.0,253.0,255.0,63.0,96.0,205.0,251.0,253.0,205.0,111.0,4.0,96.0,189.0,251.0,251.0,253.0,251.0,251.0,31.0,16.0,64.0,223.0,244.0,251.0,251.0,211.0,213.0,251.0,251.0,31.0,80.0,181.0,251.0,253.0,251.0,251.0,251.0,94.0,96.0,251.0,251.0,31.0,92.0,253.0,253.0,253.0,255.0,253.0,253.0,253.0,95.0,96.0,253.0,253.0,31.0,92.0,236.0,251.0,243.0,220.0,233.0,251.0,251.0,243.0,82.0,96.0,251.0,251.0,31.0,80.0,253.0,251.0,251.0,188.0,96.0,251.0,251.0,109.0,96.0,251.0,251.0,31.0,96.0,240.0,253.0,243.0,188.0,42.0,96.0,204.0,109.0,4.0,12.0,197.0,251.0,31.0,221.0,251.0,253.0,121.0,36.0,23.0,190.0,251.0,31.0,48.0,234.0,253.0,191.0,253.0,31.0,44.0,221.0,251.0,251.0,12.0,197.0,251.0,31.0,190.0,251.0,251.0,251.0,96.0,251.0,251.0,31.0,190.0,251.0,251.0,113.0,40.0,234.0,251.0,219.0,23.0,190.0,251.0,251.0,94.0,40.0,217.0,253.0,231.0,47.0,191.0,253.0,253.0,253.0,12.0,174.0,253.0,253.0,219.0,39.0,67.0,236.0,251.0,251.0,191.0,190.0,111.0,72.0,190.0,191.0,197.0,251.0,243.0,121.0,39.0,63.0,236.0,251.0,253.0,251.0,251.0,251.0,251.0,253.0,251.0,188.0,94.0,27.0,129.0,253.0,251.0,251.0,251.0,251.0,229.0,168.0,15.0,95.0,212.0,251.0,211.0,94.0,59.0])),\n",
              " LabeledPoint(1.0, (692,[158,159,160,185,186,187,188,189,212,213,214,215,216,217,240,241,242,243,244,267,268,269,270,271,272,295,296,297,298,299,323,324,325,326,350,351,352,353,354,377,378,379,380,381,404,405,406,407,408,432,433,434,435,436,459,460,461,462,463,486,487,488,489,490,513,514,515,516,517,541,542,543,544,545,569,570,571,572,573,597,598,599,600,624,625,626,627,628,652,653,654,655,681,682,683],[121.0,254.0,136.0,13.0,230.0,253.0,248.0,99.0,4.0,118.0,253.0,253.0,225.0,42.0,61.0,253.0,253.0,253.0,74.0,32.0,206.0,253.0,253.0,186.0,9.0,211.0,253.0,253.0,239.0,69.0,254.0,253.0,253.0,133.0,142.0,255.0,253.0,186.0,8.0,149.0,229.0,254.0,207.0,21.0,54.0,229.0,253.0,254.0,105.0,152.0,254.0,254.0,213.0,26.0,112.0,251.0,253.0,253.0,26.0,29.0,212.0,253.0,250.0,149.0,36.0,214.0,253.0,253.0,137.0,75.0,253.0,253.0,253.0,59.0,93.0,253.0,253.0,189.0,17.0,224.0,253.0,253.0,84.0,43.0,235.0,253.0,126.0,1.0,99.0,248.0,253.0,119.0,225.0,235.0,49.0])),\n",
              " LabeledPoint(1.0, (692,[99,100,101,127,128,129,130,154,155,156,157,158,182,183,184,185,186,209,210,211,212,213,237,238,239,240,241,264,265,266,267,268,269,291,292,293,294,295,296,297,314,315,316,317,318,319,320,321,322,323,324,325,342,343,344,345,346,347,348,349,350,351,352,353,371,372,373,374,378,379,380,381,406,407,408,409,435,436,437,463,464,465,491,492,493,514,515,516,517,518,519,520,521,522,523,524,525,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,594,595,596,597,598,599,600,622,623,624,625],[166.0,222.0,55.0,197.0,254.0,218.0,5.0,29.0,249.0,254.0,254.0,9.0,45.0,254.0,254.0,174.0,2.0,4.0,164.0,254.0,254.0,85.0,146.0,254.0,254.0,254.0,85.0,101.0,245.0,254.0,254.0,254.0,85.0,97.0,248.0,254.0,204.0,254.0,254.0,85.0,12.0,59.0,98.0,151.0,237.0,254.0,254.0,109.0,35.0,254.0,254.0,85.0,41.0,216.0,254.0,254.0,239.0,153.0,37.0,4.0,32.0,254.0,254.0,85.0,7.0,44.0,44.0,30.0,32.0,254.0,254.0,96.0,19.0,230.0,254.0,174.0,197.0,254.0,110.0,197.0,254.0,85.0,197.0,253.0,63.0,37.0,54.0,54.0,45.0,26.0,84.0,221.0,84.0,21.0,31.0,162.0,78.0,6.0,41.0,141.0,244.0,254.0,254.0,248.0,236.0,254.0,254.0,254.0,233.0,239.0,254.0,138.0,23.0,167.0,254.0,254.0,254.0,254.0,229.0,228.0,185.0,138.0,138.0,138.0,138.0,138.0,138.0,44.0,113.0,254.0,254.0,254.0,179.0,64.0,5.0,32.0,209.0,183.0,97.0])),\n",
              " LabeledPoint(0.0, (692,[154,155,156,157,158,159,182,183,184,185,186,187,188,189,208,209,210,211,212,213,214,215,216,217,236,237,238,239,240,241,242,243,244,245,264,265,266,267,268,269,270,271,272,273,290,291,292,293,294,295,298,299,300,301,318,319,320,321,322,326,327,328,329,346,347,348,349,350,353,354,355,356,357,374,375,376,377,378,381,382,383,384,385,402,403,404,405,406,409,410,411,412,413,429,430,431,432,437,438,439,440,456,457,458,459,460,464,465,466,467,468,484,485,486,487,488,491,492,493,494,495,512,513,514,515,516,519,520,521,522,523,540,541,542,543,544,546,547,548,549,550,551,568,569,570,571,572,573,574,575,576,577,596,597,598,599,600,601,602,603,604,605,624,625,626,627,628,629,630,631,632,633,653,654,655,656,657,658,682,683,684,685,686],[53.0,255.0,253.0,253.0,253.0,124.0,180.0,253.0,251.0,251.0,251.0,251.0,145.0,62.0,32.0,217.0,241.0,253.0,251.0,251.0,251.0,251.0,253.0,107.0,37.0,251.0,251.0,253.0,251.0,251.0,251.0,251.0,253.0,107.0,166.0,251.0,251.0,253.0,251.0,96.0,148.0,251.0,253.0,107.0,73.0,253.0,253.0,253.0,253.0,130.0,110.0,253.0,255.0,108.0,73.0,251.0,251.0,251.0,251.0,109.0,251.0,253.0,107.0,202.0,251.0,251.0,251.0,225.0,6.0,129.0,251.0,253.0,107.0,150.0,251.0,251.0,251.0,71.0,115.0,251.0,251.0,253.0,107.0,253.0,251.0,251.0,173.0,20.0,217.0,251.0,251.0,253.0,107.0,182.0,255.0,253.0,216.0,218.0,253.0,253.0,182.0,63.0,221.0,253.0,251.0,215.0,84.0,236.0,251.0,251.0,77.0,109.0,251.0,253.0,251.0,215.0,11.0,160.0,251.0,251.0,96.0,109.0,251.0,253.0,251.0,137.0,150.0,251.0,251.0,251.0,71.0,109.0,251.0,253.0,251.0,35.0,130.0,253.0,251.0,251.0,173.0,20.0,110.0,253.0,255.0,253.0,98.0,150.0,253.0,255.0,253.0,164.0,109.0,251.0,253.0,251.0,251.0,251.0,251.0,253.0,251.0,35.0,93.0,241.0,253.0,251.0,251.0,251.0,251.0,216.0,112.0,5.0,103.0,253.0,251.0,251.0,251.0,251.0,124.0,251.0,225.0,71.0,71.0])),\n",
              " LabeledPoint(0.0, (692,[127,128,129,130,131,155,156,157,158,159,181,182,183,184,185,186,187,209,210,211,212,213,214,215,216,237,238,239,240,241,242,243,244,245,263,264,265,266,267,268,269,270,271,272,273,291,292,293,294,295,296,297,298,299,300,301,302,317,318,319,320,321,322,323,324,325,326,327,328,329,330,344,345,346,347,348,349,353,354,355,356,357,358,372,373,374,375,376,377,381,382,383,384,385,386,399,400,401,402,403,404,409,410,411,412,413,414,427,428,429,430,431,437,438,439,440,441,455,456,457,458,459,460,465,466,467,468,483,484,485,486,487,488,491,492,493,494,495,496,511,512,513,514,515,519,520,521,522,523,539,540,541,542,543,544,545,546,547,548,549,550,567,568,569,570,571,572,573,574,575,576,577,578,595,596,597,598,599,600,601,602,603,604,605,623,624,625,626,627,628,629,630,631,652,653,654,655,656,657,658],[73.0,253.0,227.0,73.0,21.0,73.0,251.0,251.0,251.0,174.0,16.0,166.0,228.0,251.0,251.0,251.0,122.0,62.0,220.0,253.0,251.0,251.0,251.0,251.0,79.0,79.0,231.0,253.0,251.0,251.0,251.0,251.0,232.0,77.0,145.0,253.0,253.0,253.0,255.0,253.0,253.0,253.0,253.0,255.0,108.0,144.0,251.0,251.0,251.0,253.0,168.0,107.0,169.0,251.0,253.0,189.0,20.0,27.0,89.0,236.0,251.0,235.0,215.0,164.0,15.0,6.0,129.0,251.0,253.0,251.0,35.0,47.0,211.0,253.0,251.0,251.0,142.0,37.0,251.0,251.0,253.0,251.0,35.0,109.0,251.0,253.0,251.0,251.0,142.0,11.0,148.0,251.0,253.0,251.0,164.0,11.0,150.0,253.0,255.0,211.0,25.0,11.0,150.0,253.0,255.0,211.0,25.0,140.0,251.0,251.0,253.0,107.0,37.0,251.0,251.0,211.0,46.0,190.0,251.0,251.0,253.0,128.0,5.0,37.0,251.0,251.0,51.0,115.0,251.0,251.0,253.0,188.0,20.0,32.0,109.0,129.0,251.0,173.0,103.0,217.0,251.0,251.0,201.0,30.0,73.0,251.0,251.0,251.0,71.0,166.0,253.0,253.0,255.0,149.0,73.0,150.0,253.0,255.0,253.0,253.0,143.0,140.0,251.0,251.0,253.0,251.0,251.0,251.0,251.0,253.0,251.0,230.0,61.0,190.0,251.0,251.0,253.0,251.0,251.0,251.0,251.0,242.0,215.0,55.0,21.0,189.0,251.0,253.0,251.0,251.0,251.0,173.0,103.0,31.0,200.0,253.0,251.0,96.0,71.0,20.0]))]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numClasses = 2\n",
        "categoricalFeaturesInfo = {}\n",
        "impurity = \"gini\"\n",
        "\n",
        "model = DecisionTree.trainClassifier(trainingData, numClasses, categoricalFeaturesInfo,\n",
        "  impurity)"
      ],
      "metadata": {
        "id": "vEw7hMHsatv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(testData.map(lambda x: x.features))\n",
        "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
        "testErr = labelsAndPredictions.filter(\n",
        "    lambda lp: lp[0] != lp[1]).count() / float(testData.count())\n",
        "print('Test Error = ' + str(testErr))\n",
        "print('Learned classification tree model:')\n",
        "print(model.toDebugString())"
      ],
      "metadata": {
        "id": "XmTnplvuETu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4dcb6e-9fc3-4a90-8dd2-41cf503fb027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.06060606060606061\n",
            "Learned classification tree model:\n",
            "DecisionTreeModel classifier of depth 1 with 3 nodes\n",
            "  If (feature 406 <= 22.0)\n",
            "   Predict: 0.0\n",
            "  Else (feature 406 > 22.0)\n",
            "   Predict: 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./bin/pyspark"
      ],
      "metadata": {
        "id": "6AW9M4gSrviR",
        "outputId": "5de512de-a8ce-4bcc-a778-ec97498bfbd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: ./bin/pyspark: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(sc, \"myDecisionTreeClassificationModel.dt\")\n",
        "sameModel = DecisionTreeModel.load(sc, \"myDecisionTreeClassificationModel.dt\")"
      ],
      "metadata": {
        "id": "od6iDkJhIVm8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dafb479d-2c6a-4470-8c13-e990db8cd07f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-e42e5d6bf58b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"myDecisionTreeClassificationModel.dt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msameModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"myDecisionTreeClassificationModel.dt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop3.2/python/pyspark/mllib/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sc, path)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path should be a string, got type %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop3.2/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop3.2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.2-bin-hadoop3.2/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o310.save.\n: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/content/myDecisionTreeClassificationModel.dt/metadata already exists\n\tat org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)\n\tat org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:299)\n\tat org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1090)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1088)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1061)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1026)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1008)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1007)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$2(PairRDDFunctions.scala:964)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:962)\n\tat org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$2(RDD.scala:1578)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1578)\n\tat org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$1(RDD.scala:1564)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1564)\n\tat org.apache.spark.mllib.tree.model.DecisionTreeModel$SaveLoadV1_0$.save(DecisionTreeModel.scala:227)\n\tat org.apache.spark.mllib.tree.model.DecisionTreeModel.save(DecisionTreeModel.scala:127)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n"
          ]
        }
      ]
    }
  ]
}