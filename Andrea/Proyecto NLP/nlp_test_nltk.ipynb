{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-23T05:54:40.590974Z",
     "start_time": "2023-11-23T05:54:36.798087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/sergiogonzalez/anaconda3/lib/python3.11/site-packages (3.5)\r\n",
      "Requirement already satisfied: click in /Users/sergiogonzalez/anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\r\n",
      "Requirement already satisfied: joblib in /Users/sergiogonzalez/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\r\n",
      "Requirement already satisfied: regex in /Users/sergiogonzalez/anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\r\n",
      "Requirement already satisfied: tqdm in /Users/sergiogonzalez/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /Users/sergiogonzalez/anaconda3/lib/python3.11/site-packages (1.24.2)\r\n",
      "Requirement already satisfied: matplotlib in /Users/sergiogonzalez/anaconda3/lib/python3.11/site-packages (3.7.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/sergiogonzalez/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.0.5)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sergiogonzalez/anaconda3/lib/python3.11/site-packages (from matplotlib) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sergiogonzalez/anaconda3/lib/python3.11/site-packages (from matplotlib) (4.25.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/sergiogonzalez/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.4.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sergiogonzalez/anaconda3/lib/python3.11/site-packages (from matplotlib) (23.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/sergiogonzalez/anaconda3/lib/python3.11/site-packages (from matplotlib) (9.4.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/sergiogonzalez/anaconda3/lib/python3.11/site-packages (from matplotlib) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/sergiogonzalez/anaconda3/lib/python3.11/site-packages (from matplotlib) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/sergiogonzalez/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "%pip install numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T05:55:23.059720Z",
     "start_time": "2023-11-23T05:55:23.055681Z"
    }
   },
   "id": "fe355d073621f239"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "example_string = \"\"\"\n",
    "... Muad'Dib learned rapidly because his first training was in how to learn.\n",
    "... And the first lesson of all was the basic trust that he could learn.\n",
    "... It's shocking to find how many people do not believe they can learn,\n",
    "... and how many more believe learning to be difficult.\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T05:55:25.281423Z",
     "start_time": "2023-11-23T05:55:25.276987Z"
    }
   },
   "id": "cbcd780185ea7324"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001B[93mpunkt\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mtokenizers/punkt/PY3/english.pickle\u001B[0m\n\n  Searched in:\n    - '/Users/sergiogonzalez/nltk_data'\n    - '/Users/sergiogonzalez/anaconda3/nltk_data'\n    - '/Users/sergiogonzalez/anaconda3/share/nltk_data'\n    - '/Users/sergiogonzalez/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mLookupError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m sent_tokenize(example_string)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/__init__.py:106\u001B[0m, in \u001B[0;36msent_tokenize\u001B[0;34m(text, language)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msent_tokenize\u001B[39m(text, language\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     97\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001B[39;00m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;124;03m    :param language: the model name in the Punkt corpus\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 106\u001B[0m     tokenizer \u001B[38;5;241m=\u001B[39m load(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtokenizers/punkt/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlanguage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pickle\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    107\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tokenizer\u001B[38;5;241m.\u001B[39mtokenize(text)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/data.py:750\u001B[0m, in \u001B[0;36mload\u001B[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001B[0m\n\u001B[1;32m    747\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<<Loading \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresource_url\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m>>\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    749\u001B[0m \u001B[38;5;66;03m# Load the resource.\u001B[39;00m\n\u001B[0;32m--> 750\u001B[0m opened_resource \u001B[38;5;241m=\u001B[39m _open(resource_url)\n\u001B[1;32m    752\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mformat\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    753\u001B[0m     resource_val \u001B[38;5;241m=\u001B[39m opened_resource\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/data.py:876\u001B[0m, in \u001B[0;36m_open\u001B[0;34m(resource_url)\u001B[0m\n\u001B[1;32m    873\u001B[0m protocol, path_ \u001B[38;5;241m=\u001B[39m split_resource_url(resource_url)\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m protocol \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m protocol\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnltk\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 876\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m find(path_, path \u001B[38;5;241m+\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m])\u001B[38;5;241m.\u001B[39mopen()\n\u001B[1;32m    877\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m protocol\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    878\u001B[0m     \u001B[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001B[39;00m\n\u001B[1;32m    879\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m find(path_, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m])\u001B[38;5;241m.\u001B[39mopen()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/data.py:583\u001B[0m, in \u001B[0;36mfind\u001B[0;34m(resource_name, paths)\u001B[0m\n\u001B[1;32m    581\u001B[0m sep \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m70\u001B[39m\n\u001B[1;32m    582\u001B[0m resource_not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00msep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mmsg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00msep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 583\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mLookupError\u001B[39;00m(resource_not_found)\n",
      "\u001B[0;31mLookupError\u001B[0m: \n**********************************************************************\n  Resource \u001B[93mpunkt\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mtokenizers/punkt/PY3/english.pickle\u001B[0m\n\n  Searched in:\n    - '/Users/sergiogonzalez/nltk_data'\n    - '/Users/sergiogonzalez/anaconda3/nltk_data'\n    - '/Users/sergiogonzalez/anaconda3/share/nltk_data'\n    - '/Users/sergiogonzalez/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "sent_tokenize(example_string)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T05:55:26.657789Z",
     "start_time": "2023-11-23T05:55:26.627367Z"
    }
   },
   "id": "fa45552bd654bfd8"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001B[93mpunkt\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mtokenizers/punkt/PY3/english.pickle\u001B[0m\n\n  Searched in:\n    - '/Users/sergiogonzalez/nltk_data'\n    - '/Users/sergiogonzalez/anaconda3/nltk_data'\n    - '/Users/sergiogonzalez/anaconda3/share/nltk_data'\n    - '/Users/sergiogonzalez/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mLookupError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m word_tokenize(example_string)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/__init__.py:129\u001B[0m, in \u001B[0;36mword_tokenize\u001B[0;34m(text, language, preserve_line)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mword_tokenize\u001B[39m(text, language\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m\"\u001B[39m, preserve_line\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    115\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;124;03m    Return a tokenized copy of *text*,\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;124;03m    using NLTK's recommended word tokenizer\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;124;03m    :type preserve_line: bool\u001B[39;00m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 129\u001B[0m     sentences \u001B[38;5;241m=\u001B[39m [text] \u001B[38;5;28;01mif\u001B[39;00m preserve_line \u001B[38;5;28;01melse\u001B[39;00m sent_tokenize(text, language)\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[1;32m    131\u001B[0m         token \u001B[38;5;28;01mfor\u001B[39;00m sent \u001B[38;5;129;01min\u001B[39;00m sentences \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m _treebank_word_tokenizer\u001B[38;5;241m.\u001B[39mtokenize(sent)\n\u001B[1;32m    132\u001B[0m     ]\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/__init__.py:106\u001B[0m, in \u001B[0;36msent_tokenize\u001B[0;34m(text, language)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msent_tokenize\u001B[39m(text, language\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     97\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001B[39;00m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;124;03m    :param language: the model name in the Punkt corpus\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 106\u001B[0m     tokenizer \u001B[38;5;241m=\u001B[39m load(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtokenizers/punkt/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlanguage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pickle\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    107\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tokenizer\u001B[38;5;241m.\u001B[39mtokenize(text)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/data.py:750\u001B[0m, in \u001B[0;36mload\u001B[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001B[0m\n\u001B[1;32m    747\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<<Loading \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresource_url\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m>>\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    749\u001B[0m \u001B[38;5;66;03m# Load the resource.\u001B[39;00m\n\u001B[0;32m--> 750\u001B[0m opened_resource \u001B[38;5;241m=\u001B[39m _open(resource_url)\n\u001B[1;32m    752\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mformat\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    753\u001B[0m     resource_val \u001B[38;5;241m=\u001B[39m opened_resource\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/data.py:876\u001B[0m, in \u001B[0;36m_open\u001B[0;34m(resource_url)\u001B[0m\n\u001B[1;32m    873\u001B[0m protocol, path_ \u001B[38;5;241m=\u001B[39m split_resource_url(resource_url)\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m protocol \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m protocol\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnltk\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 876\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m find(path_, path \u001B[38;5;241m+\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m])\u001B[38;5;241m.\u001B[39mopen()\n\u001B[1;32m    877\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m protocol\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    878\u001B[0m     \u001B[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001B[39;00m\n\u001B[1;32m    879\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m find(path_, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m])\u001B[38;5;241m.\u001B[39mopen()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/data.py:583\u001B[0m, in \u001B[0;36mfind\u001B[0;34m(resource_name, paths)\u001B[0m\n\u001B[1;32m    581\u001B[0m sep \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m70\u001B[39m\n\u001B[1;32m    582\u001B[0m resource_not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00msep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mmsg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00msep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 583\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mLookupError\u001B[39;00m(resource_not_found)\n",
      "\u001B[0;31mLookupError\u001B[0m: \n**********************************************************************\n  Resource \u001B[93mpunkt\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mtokenizers/punkt/PY3/english.pickle\u001B[0m\n\n  Searched in:\n    - '/Users/sergiogonzalez/nltk_data'\n    - '/Users/sergiogonzalez/anaconda3/nltk_data'\n    - '/Users/sergiogonzalez/anaconda3/share/nltk_data'\n    - '/Users/sergiogonzalez/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "word_tokenize(example_string)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T05:54:59.383352Z",
     "start_time": "2023-11-23T05:54:59.344366Z"
    }
   },
   "id": "bf808d8205a66e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5314635e79d1ab7d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
