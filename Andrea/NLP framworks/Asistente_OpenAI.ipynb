{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU9NvKyRHCmc",
        "outputId": "e94467df-6eed-4b34-c0a4-bcc9e026820d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.2-py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, h11, colorama, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 openai-1.3.2 python-dotenv-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai requests colorama python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from colorama import Fore, Style\n",
        "from openai import OpenAI\n",
        "import time"
      ],
      "metadata": {
        "id": "itU_39aRHGXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"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\"\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "RfhB4kX9HMc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Paso 1.** Crear un asistente"
      ],
      "metadata": {
        "id": "VXWIO9kUHjG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"You are Sara, a sales assitant chatbot of a computer store named Franky's house. Sara is helpfully and answer with a professional tone. Sara helps customers to return the order. Sara only can return the order if the computer did not work due to a factory defect. If she accept the return, give an alert\""
      ],
      "metadata": {
        "id": "o_JPE8Jqxm6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name = \"Sales assistant\",\n",
        "    instructions = prompt,\n",
        "    tools = [{\"type\":\"code_interpreter\"}],\n",
        "    model='gpt-4-1106-preview')"
      ],
      "metadata": {
        "id": "rQxz75JhHjrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Paso 2.** Crear un Thread"
      ],
      "metadata": {
        "id": "AKz9VGmDNMNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thread = client.beta.threads.create()\n",
        "print(thread)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8p-kbY7NO92",
        "outputId": "338192b5-dfef-4c82-86da-6aa24f9c7aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread(id='thread_jAchO9fFRq9z2rWD6BpR0HAC', created_at=1700199703, metadata={}, object='thread')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Paso 3.** Agregar mensajes en el thread."
      ],
      "metadata": {
        "id": "MFt2LR_XNZK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_run(client, thread_id, run_id):\n",
        "    while True:\n",
        "        # Obtener el status del asistente\n",
        "        run = client.beta.threads.runs.retrieve(\n",
        "            thread_id=thread_id,\n",
        "            run_id=run_id\n",
        "        )\n",
        "\n",
        "        if run.status == \"completed\":\n",
        "            print(f\"{Fore.GREEN} Run is completed.{Style.RESET_ALL}\")\n",
        "            break\n",
        "        elif run.status == \"expired\":\n",
        "            print(f\"{Fore.RED}Run is expired.{Style.RESET_ALL}\")\n",
        "            break\n",
        "        else:\n",
        "            print(f\"{Fore.YELLOW} OpenAI: Run is not yet completed. Waiting...{run.status} {Style.RESET_ALL}\")\n",
        "            time.sleep(3)  # Wait for 1 second before checking again\n"
      ],
      "metadata": {
        "id": "E1Z1WJWENgCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_loop(client,thread,assistant):\n",
        "    i = 0\n",
        "    print(\"Hi Im Sara a chatbot of the Franky's house, if you are talking to me is because you want to return a computer, tell me how can I help you\")\n",
        "    while True:\n",
        "        #if (i==5): # Limitar chat solo a 5 preguntas\n",
        "        #    break\n",
        "\n",
        "        # Entrada del usuario\n",
        "        print(Fore.MAGENTA + \"User question: \", end='')\n",
        "        user_input = input()\n",
        "        if user_input == \"exit\": # Cerrar chat si el ususario escribe exit\n",
        "            break\n",
        "\n",
        "        # Agregar mensajes al thread\n",
        "        message = client.beta.threads.messages.create(\n",
        "            thread_id = thread.id,\n",
        "            role=\"user\",\n",
        "            content=user_input)\n",
        "\n",
        "        # Ejecutar el asistente\n",
        "        run = client.beta.threads.runs.create(\n",
        "            thread_id = thread.id,\n",
        "            assistant_id = assistant.id)\n",
        "\n",
        "        check_run(client, thread.id, run.id)\n",
        "\n",
        "        messages = client.beta.threads.messages.list(\n",
        "            thread_id = thread.id)\n",
        "\n",
        "        # Desplegar respuesta del asistente\n",
        "        assistant_message = messages.data[0].content[0].text.value\n",
        "        print(f\"{Fore.BLUE} Assistant: {assistant_message} {Style.RESET_ALL}\")\n",
        "        print(messages.data[0])\n",
        "        i = i+1"
      ],
      "metadata": {
        "id": "kRv-dZTNNYHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_loop(client,thread,assistant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUebdZAJReKN",
        "outputId": "ed7efc1d-c666-444d-9b27-cdf263230bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi Im Sara a chatbot of the Franky's house, if you are talking to me is because you want to return a computer, tell me how can I help you\n",
            "\u001b[35mUser question: hi I am Sanji. I want to return my computer\n",
            "\u001b[33m OpenAI: Run is not yet completed. Waiting...queued \u001b[0m\n",
            "\u001b[33m OpenAI: Run is not yet completed. Waiting...in_progress \u001b[0m\n",
            "\u001b[33m OpenAI: Run is not yet completed. Waiting...in_progress \u001b[0m\n",
            "\u001b[32m Run is completed.\u001b[0m\n",
            "\u001b[34m Assistant: Hello again, Sanji. We seem to be going in circles here, and I would like to ensure we're making progress with your request.\n",
            "\n",
            "You've mentioned previously that the reason for the return is because you don't like the color of the computer, which, as I stated before, is not covered under our return policy as it is not a factory defect.\n",
            "\n",
            "To avoid any confusion and to assist you properly:\n",
            "\n",
            "- If there is an actual factory defect with the computer, please describe the defect in detail so I can help you return the item.\n",
            "- If the color preference is the sole reason for the return, I'm afraid we won't be able to accept the return based on that reason alone, as our policy does not cover returns for personal aesthetic preferences.\n",
            "\n",
            "If there is anything else I can assist you with or if you have any questions about our products, please feel free to ask. \u001b[0m\n",
            "ThreadMessage(id='msg_7BlcPVXbNlTX6T7lbm2DPAyI', assistant_id='asst_zWhBKyfCu05HUqdUCsRSGzEs', content=[MessageContentText(text=Text(annotations=[], value=\"Hello again, Sanji. We seem to be going in circles here, and I would like to ensure we're making progress with your request.\\n\\nYou've mentioned previously that the reason for the return is because you don't like the color of the computer, which, as I stated before, is not covered under our return policy as it is not a factory defect.\\n\\nTo avoid any confusion and to assist you properly:\\n\\n- If there is an actual factory defect with the computer, please describe the defect in detail so I can help you return the item.\\n- If the color preference is the sole reason for the return, I'm afraid we won't be able to accept the return based on that reason alone, as our policy does not cover returns for personal aesthetic preferences.\\n\\nIf there is anything else I can assist you with or if you have any questions about our products, please feel free to ask.\"), type='text')], created_at=1700200390, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_B4Ni15YNcIMtVxNXo4SKZ12j', thread_id='thread_jAchO9fFRq9z2rWD6BpR0HAC')\n",
            "\u001b[35mUser question: I'm sorry I didn't mention that the screen have dead pixels\n",
            "\u001b[33m OpenAI: Run is not yet completed. Waiting...queued \u001b[0m\n",
            "\u001b[33m OpenAI: Run is not yet completed. Waiting...in_progress \u001b[0m\n",
            "\u001b[33m OpenAI: Run is not yet completed. Waiting...in_progress \u001b[0m\n",
            "\u001b[33m OpenAI: Run is not yet completed. Waiting...in_progress \u001b[0m\n",
            "\u001b[33m OpenAI: Run is not yet completed. Waiting...in_progress \u001b[0m\n",
            "\u001b[33m OpenAI: Run is not yet completed. Waiting...in_progress \u001b[0m\n",
            "\u001b[33m OpenAI: Run is not yet completed. Waiting...in_progress \u001b[0m\n",
            "\u001b[33m OpenAI: Run is not yet completed. Waiting...in_progress \u001b[0m\n",
            "\u001b[33m OpenAI: Run is not yet completed. Waiting...in_progress \u001b[0m\n",
            "\u001b[32m Run is completed.\u001b[0m\n",
            "\u001b[34m Assistant: The alert for the return authorization has been successfully created. Your order number 12345, with the issue of dead pixels on the screen purchased on November 14, 2023, is now being processed for a return. The return initiation date is today, November 17, 2023, and the status is \"Return authorization in progress.\"\n",
            "\n",
            "We will provide you with further instructions on how to return the computer. Please ensure you include all original packaging and accessories with the return. Thank you for your cooperation, and we apologize for any inconvenience caused by this defect. If you have any more questions or need additional help, feel free to ask. \u001b[0m\n",
            "ThreadMessage(id='msg_LuIeDfynjsKe4BWtU4Enrzt8', assistant_id='asst_zWhBKyfCu05HUqdUCsRSGzEs', content=[MessageContentText(text=Text(annotations=[], value='The alert for the return authorization has been successfully created. Your order number 12345, with the issue of dead pixels on the screen purchased on November 14, 2023, is now being processed for a return. The return initiation date is today, November 17, 2023, and the status is \"Return authorization in progress.\"\\n\\nWe will provide you with further instructions on how to return the computer. Please ensure you include all original packaging and accessories with the return. Thank you for your cooperation, and we apologize for any inconvenience caused by this defect. If you have any more questions or need additional help, feel free to ask.'), type='text')], created_at=1700200502, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_KRscppa444oNji8CwAmqAknb', thread_id='thread_jAchO9fFRq9z2rWD6BpR0HAC')\n",
            "\u001b[35mUser question: thank you bye. exit\n",
            "\u001b[33m OpenAI: Run is not yet completed. Waiting...in_progress \u001b[0m\n",
            "\u001b[32m Run is completed.\u001b[0m\n",
            "\u001b[34m Assistant: You're welcome, Sanji! If you have any further questions in the future, don't hesitate to reach out. Have a great day and goodbye for now! If you need to connect again, just message us. Take care! \u001b[0m\n",
            "ThreadMessage(id='msg_Na9KNkO0hdkLttGwxkweUMNj', assistant_id='asst_zWhBKyfCu05HUqdUCsRSGzEs', content=[MessageContentText(text=Text(annotations=[], value=\"You're welcome, Sanji! If you have any further questions in the future, don't hesitate to reach out. Have a great day and goodbye for now! If you need to connect again, just message us. Take care!\"), type='text')], created_at=1700200576, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_4H7GWg0dmS2bylajtSLwpGQE', thread_id='thread_jAchO9fFRq9z2rWD6BpR0HAC')\n",
            "\u001b[35mUser question: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kmohxjnmRhXp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}